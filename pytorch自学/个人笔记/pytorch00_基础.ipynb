{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch基本知识-Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0 10.2\n"
     ]
    }
   ],
   "source": [
    "# first of all, import pytorch\n",
    "import torch\n",
    "\n",
    "print(torch.__version__, torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor的生成\n",
    "\n",
    "tensor 是pytorch以及深度学习中默认的数据格式，是最基本的组成单元。虽然可以使用torch.Tensor()构建一个张量，但是不推荐，因为这个默认是32bit-float类型的数据；相反的，**推荐使用工厂函数，like torch.empty()、torch.zeros()、torch.ones()，并用dtype指定数据类型**。\n",
    "```python\n",
    "tensor = torch.empty((2, 3), dtype=torch.float64)  # 构造一个 torch.DoubleTensor (float64)\n",
    "\n",
    "tensor = torch.zeros((3, 3), dtype=torch.int32)  # 构造一个 torch.IntTensor (int32)\n",
    "\n",
    "tensor = torch.ones((4, 4), dtype=torch.bool)  # 构造一个 torch.BoolTensor\n",
    "\n",
    "```\n",
    "\n",
    "同时，torch.tensor()总是会复制你的数据，如果不需要为其计算梯度，可以使用下面的方法：\n",
    "```python\n",
    "data = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)\n",
    "data.requires_grad_()  # 现在 requires_grad=True, 并且没有创建副本\n",
    "\n",
    "data = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "no_grad_data = data.detach()  # 生成不需要梯度的新张量，数据存储是共享的\n",
    "\n",
    "```\n",
    "\n",
    "如果有一个Numpy数组，并想转为tensor类型，推荐如下操作，因为这直接使用numpy的内存地址，而不需要新建。\n",
    "```python\n",
    "import numpy as np\n",
    "np_array = np.array([1.0, 2.0, 3.0])\n",
    "tensor = torch.as_tensor(np_array)  # 不进行内存拷贝，直接使用相同的内存\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor的形状\n",
    "\n",
    "tensor.ndim 指的是张量（Tensor）的维度数量，也称为“张量的阶数”或“张量的秩”。它表示张量的结构有多少个维度（轴），可以理解为该张量是几维数组。标量是 0 维的，向量是 1 维的，矩阵是 2 维的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # 将标量tensor变为一个数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimension of a vector is : 1\n",
      "the shape of a vector is : torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print('the dimension of a vector is :',vector.ndim )\n",
    "print('the shape of a vector is :', vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[7,8],[5,6]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensions of a matrix is : 2\n",
      "the shape of a matrix is : torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print('the dimensions of a matrix is :',matrix.ndim)\n",
    "print('the shape of a matrix is :',matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dimensions of a tensor is 3\n",
      "the shape of a tensor is torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print('the dimensions of a tensor is',tensor.ndim)\n",
    "print('the shape of a tensor is',tensor.shape) # 由外向内看中括号，中括号间的逗号数就代表数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor工厂函数生成\n",
    "\n",
    "深度学习参数更新过程\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
    "\n",
    "下面使用随机方法构建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8867, 0.6970, 0.6490, 0.2785],\n",
       "         [0.0348, 0.0394, 0.8291, 0.6344],\n",
       "         [0.0157, 0.0036, 0.4928, 0.8933]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size = (3,4)) # 用tuple数据类型指定生成的格式\n",
    "random_tensor,random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size = (3,4))\n",
    "zeros,zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (3, 4))\n",
    "ones,ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86182\\AppData\\Local\\Temp\\ipykernel_28860\\232764869.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated \n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten)\n",
    "ten_zeros\n",
    "\n",
    "ten_ones = torch.ones_like(zero_to_ten)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor的三件套\n",
    "\n",
    "在实际操作中，引起报错的主要原因往往是tensor的数据格式不一致、数据类型不一致、数据不在同一个设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float16, device(type='cpu'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=torch.float16)\n",
    "float_16_tensor.shape,float_16_tensor.dtype, float_16_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作tensor\n",
    "\n",
    "深度学习中，数据基本都是以tensor来展现的。模型学习数据中的特征也是通过大量的运算得到的，就是基本的四则运算以及矩阵操作等。四则运算并不会改变tensor内部的值，除非被重新分配 tensor = ...。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11, 12, 13]), tensor([10, 20, 30]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10,tensor * 10, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵乘法\n",
    "\n",
    "最重要的运算操作就是矩阵乘法-> @，只需要满足inner dimensions match and the resulting matrix has the shape of the outer dimensions. thats all.\n",
    "注意矩阵的乘法和元素的乘法（*）是不一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1608, 0.8483, 0.9520],\n",
       "         [1.1274, 0.9002, 1.2802],\n",
       "         [1.4138, 1.0658, 1.5958]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.rand(size = (3,4))\n",
    "tensor2 = torch.rand(size = (4,3))\n",
    "tensor = tensor1 @ tensor2\n",
    "tensor,tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[ 1.0348,  0.4592,  0.3892,  0.0690,  0.3858,  0.3514],\n",
      "        [ 0.9272,  0.3378,  0.3622, -0.0094,  0.4842,  0.3286],\n",
      "        [ 1.1711,  0.5868,  0.4136,  0.1433,  0.2987,  0.3971]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# 设置torch的随即种子\n",
    "torch.manual_seed(42)\n",
    "linear = torch.nn.Linear(in_features = 2,\n",
    "                         out_features=6)\n",
    "x = torch.rand(size=(3,2))\n",
    "out = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{out}\\n\\nOutput shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本的统计运算\n",
    "\n",
    "包括数的统计运算以及索引值的查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of x is 450\n",
      "the max num of x is 90, while the min num of x is 0\n",
      "Mean45.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "print(f'the sum of x is {sum(x)}')\n",
    "print(f'the max num of x is {x.max()}, while the min num of x is {x.min()}')\n",
    "print(f'Mean{x.type(torch.float32).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another specific datatype, otherwise the operation will fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 修改数据类型，防止出现不匹配的现象\n",
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype\n",
    "\n",
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16\n",
    "\n",
    "# Create an int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变tensor的形状\n",
    "\n",
    "只改变tensor的形状，而不改变tensor的值\n",
    "| Method | One-line description |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. | \n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,8.)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加一个维度\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped,x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用view也是可以的，同样是数据不变，格式改变\n",
    "# 但是要注意，view相当于为原有的tensor创建了一个\n",
    "# 新的数据视图，改变新的view也会导致tensor改变\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将多个tensor按照给定的维度堆积\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "# 移除维度数为1的维度，只有>=2的才会被保留\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "# squeeze的反向操作，在指定的维度上添加值为1的新维度\n",
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 改变轴的顺序\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "# shifts axis 0->1, 1->2, 2->0 对轴的顺序重新排列\n",
    "x_permuted = x_original.permute(2, 0, 1) \n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor的索引\n",
    "\n",
    "根据索引取tensor指定位置的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Second square bracket: tensor([[1, 2, 3]])\n",
      "Third square bracket: tensor([[1, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "# 也可以用：表示该维度所有元素，进行取数\n",
    "print(f\"First square bracket:\\n{x[:]}\") \n",
    "print(f\"Second square bracket: {x[:,0]}\") \n",
    "print(f\"Third square bracket: {x[:,:,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch与numpy\n",
    "\n",
    "常用的就是tensor与ndarray的互相转化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnapre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
