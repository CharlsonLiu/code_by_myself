# 机器学习模型
## Logistic回归

+ sigmoid公式：
$$
f(x)=\frac{1}{1+e^{-x}}
$$

+ sigmoid函数图像

<img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片Sigmoid_function.png" alt="Sigmoid function" style="display: block; margin: 0 auto;">

+ 导数
\[
\sigma'(x) = \sigma(x) \cdot (1 - \sigma(x))
\]

+ LR分类器 ==二分类==
+ 表达式
$$
p_i(y_i=1 \mid x_i) = \frac{1}{1+e^{-w x_i}} \\ \\
p_i(y_i=0 \mid x_i) = \frac{e^{-w x_i}}{1+e^{-w x_i}}
$$
    其中，随机变量$x_i \in \mathbb{R}^{n}$为实数，随机变量$y_i$的取值为$\{0, 1\}$，参数$w\in \mathbb{R}^{n}$。$wx_i$表示变量$x_i$与参数$w$之间的内积。

+ 几率 ： ==事件发生概率与不发生的概率的比值
$$
\eta_{i}=\frac{p_{i}}{1-p_{i}}
$$

    将等式两边化为以`e`为底的指数函数，有：
$$
e^{wx_i} =\frac{p_{i}}{1-p_{i}}
\\ \Downarrow
\\
p_i = \frac{1}{1+e^{-w x_i}}
$$
    逻辑回归本质上就是**关于事件几率的线性回归**。当然，逻辑回归和线性回归存在本质上的不同，其次在损失函数上，线性回归中的损失函数是均方误差，而 Logistic 回归的损失函数是**负对数似然（Negative Log-Likelihood）**。

+ 假设

    逻辑回归模型的基本假设是$y_i$服从伯努利分布，也称为两点分布或者$0-1$分布。即：
$$
p_i(y_i=1 \mid x_i ; w)=p_i \\
p_i(y_i=0 \mid x_i ; w)=1-p_i
$$

    将公式写在一起有：

$$
p_i(y_i \mid x_i ; w)=p_i^{y_i}\left(1-p_i\right)^{1-y_i}
$$


+ 参数估计

    设似然函数为：
$$
\prod_{i=1}^{n}p_{i}^{y_{i}}·\left(1-p_{i}\right)^{1-y_{i}}
$$
    对似然函数取负对数有：
$$
L(w)=-\sum_{i=1}^{n}\left(y_{i} \log \left(p_{i}\right)+\left(1-y_{i}\right) \log \left(1-p_{i}\right)\right)
$$
    通过最大化似然函数来对参数进行估计，在这里等价于最小化负对数似然函数 $L(w)$，同样可以得到 $w$ 的估计值。

    下面关于 $L(w)$ 对 $w$ 求导，具体步骤如下：

1. 对于任意样本$x_i$，有：

$$
\begin{aligned}
l &=-y_{i} \log \left(p_{i}\right)-\left(1-y_{i}\right) \log \left(1-p_{i}\right) \\ \\
&=-y_{i} \log \left(p_{i}\right)-\log \left(1-p_{i}\right)+y_{i} \log \left(1-p_{i}\right) \\ \\
&=-y_{i}\left(\log \left(\frac{p_{i}}{1-p_{i}}\right)\right)-\log \left(1-p_{i}\right)
\end{aligned}
$$
2. 由于几率 $\eta_{i}=\frac{p_{i}}{1-p_{i}}$，可得 ${p_i}=\frac{\eta_{i}}{1+\eta_{i}}$，代入：

$$
\begin{aligned}
l &=-y_{i} \log \left(\eta_{i}\right)-\log \left(1-\frac{\eta_{i}}{1+\eta_{i}}\right) \\ \\
&=-y_{i} \log \left(\eta_{i}\right)+\log \left({1+\eta_{i}}\right) \\ \\
&=-y_{i} \log \left(\eta_{i}\right)+\log \left(1+e^{\log \left(\eta_{i}\right)}\right)
\end{aligned}
$$
3. 对几率的对数 $\log(\eta_{i})$ 求导：

$$
\frac{d l}{d \log \left(\eta_{i}\right)}=-y_{i}+\frac{e^{\log \left(\eta_{i}\right)}}{1+e^{\log \left(\eta_{i}\right)}}=-y_{i}+p_{i}
$$

提到过，逻辑回归相当于**对事件的对数几率拟合线性回归**，即：$\log \left(\eta_{i}\right)=\log \frac{p_{i}}{1-p_{i}}=wx_i$，代入有：

$$
\frac{d l}{d \log \left(\eta_{i}\right)} 
=\frac{d l}{d (wx_i)}==-y_{i}+p_{i}
\\
\Downarrow
\\
\frac{d l}{dw}=(-y_{i}+p_{i})x_i
$$
    由于目标是最小化负对数似然函数，所以沿着梯度下降方向：
$$
w \leftarrow w-\frac{\gamma}{n} \sum_{i=1}^{n}\left(-y_{i}+p_{i}\right) x_{i}
\\
其中，\gamma为学习率
$$

## 相似性度量方法
1. **杰卡德（Jaccard）相似系数**
   
   `Jaccard` 系数是衡量**两个集合**的相似度一种指标，计算公式如下：
   $$
   sim_{uv}=\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}
   $$

   + 其中 $N(u)$，$N(v)$ 分别表示用户 $u$ 和用户 $v$ 交互物品的集合。
   
   + 对于用户 $u$ 和 $v$ ，该公式反映了两个交互物品交集的数量占这两个用户交互物品并集的数量的比例。
   
   杰卡德相似系数常用来评估**用户是否会对某物品进行打分**。
   
2. **余弦相似度**
   余弦相似度衡量了两个向量的夹角，夹角越小越相似。余弦相似度的计算如下，其与杰卡德（Jaccard）相似系数只是在分母上存在差异：
   $$
   sim_{uv}=\frac{|N(u) \cap N(v)|}{\sqrt{|N(u)|\cdot|N(v)|}}
   $$
   从向量的角度来看，令矩阵 $A$ 为用户-物品交互矩阵，矩阵的行表示用户，列表示物品。
   
   + 设用户和物品数量分别为 $m,n$，交互矩阵$A$就是一个 $m$ 行 $n$ 列的矩阵。
   
   + 矩阵中的元素均为 $0/1$。若用户 $i$ 对物品 $j$ 存在交互，那么 $A_{i,j}=1$，否则为 $0$ 。

   + 那么，用户之间的相似度为：
     $$
     sim_{uv} = cos(u,v) =\frac{u\cdot v}{|u|\cdot |v|}
     $$
   
     + 向量 $u,v$ 在形式都是 one-hot 类型，$u\cdot v$ 表示向量点积。
   
   上述用户-物品交互矩阵在现实中是十分稀疏的，为了节省内存，交互矩阵会采用**字典**进行存储。在 `sklearn` 中，余弦相似度的实现：

3. **皮尔逊相关系数**

   在用户之间的余弦相似度计算时，**将用户向量的内积展开为各元素乘积和**：
   $$
   sim_{uv} = \frac{\sum_i r_{ui}*r_{vi}}{\sqrt{\sum_i r_{ui}^2}\sqrt{\sum_i r_{vi}^2}}
   $$
   + 其中，$r_{ui},r_{vi}$ 分别表示用户 $u$ 和用户 $v$ 对物品 $i$ 是否有交互(或具体评分值)。
   
   皮尔逊相关系数计算公式：
   $$
   sim(u,v)=\frac{\sum_{i\in I}(r_{ui}-\bar r_u)(r_{vi}-\bar r_v)}{\sqrt{\sum_{i\in I }(r_{ui}-\bar r_u)^2}\sqrt{\sum_{i\in I }(r_{vi}-\bar r_v)^2}}
   $$
   + 其中，$r_{ui},r_{vi}$ 分别表示用户 $u$ 和用户 $v$ 对物品 $i$ 是否有交互(或具体评分值)；
   + $\bar r_u, \bar r_v$ 分别表示用户 $u$ 和用户 $v$ 交互的所有物品交互数量或者评分的平均值；
   
   相较于余弦相似度，皮尔逊相关系数通过使用**用户的平均分**对各独立评分进行修正，减小了用户评分偏置的影响。
   

4. **适用场景**

+ $Jaccard$ 相似度表示两个集合的交集元素个数在并集中所占的比例 ，所以适用于隐式反馈数据（0-1）。
+ 余弦相似度在度量文本相似度、用户相似度、物品相似度的时候都较为常用。
+ 皮尔逊相关度，**实际上也是一种余弦相似度。不过先对向量做了中心化**，范围在 $-1$ 到 $1$。
  + 相关度量的是两个变量的变化趋势是否一致，两个随机变量是不是同增同减。
  + 不适合用作计算布尔值向量（0-1）之间相关度。


## Use-CF & Item-CF

**示例图片**
![image-20210629232622758](http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210629232622758.png)

### user

**计算过程**
1. 计算用户之间的相似度

   + 根据几种评价指标,计算出各用户之间的相似程度。对于用户 Alice，选取出与其最相近的 $N$ 个用户。

2. 计算用户对新物品的评分预测

   + 方法一：利用目标用户与相似用户之间的相似度以及相似用户对物品的评分，来预测目标用户对候选物品的评分估计：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot R_{\mathrm{s}, \mathrm{p}}\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，权重 $w_{u,s}$ 是用户 $u$ 和用户 $s$ 的相似度， $R_{s,p}$ 是用户 $s$ 对物品 $p$ 的评分。

   + 方法二：考虑到用户评分的偏置，即有的用户喜欢打高分， 有的用户喜欢打低分的情况。公式如下：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\bar{R}_{u} + \frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot \left(R_{s, p}-\bar{R}_{s}\right)\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，$\bar{R}_{s}$ 表示用户 $s$ 对物品的历史平均评分。

3. 对用户进行物品推荐

   + 在获得用户 $u$ 对不同物品的评价预测后， 最终的推荐列表根据预测评分进行排序得到。 

### item

计算过程
1. 计算物品之间的相似度：余弦相似性或者皮尔逊相关系数。选取TopN相似物品计算评分
2. 根据选取出来的TopN，与user的计算方式相同，计算得分。

由于物品推荐存在长尾效应，需要对推荐权重进行控制，以防止推荐内容过于同质化。

* base 公式
  $$
  w_{i j}=\frac{|N(i) \bigcap N(j)|}{|N(i)|}
  $$

  + 该公式表示同时喜好物品 $i$ 和物品 $j$ 的用户数，占喜爱物品 $i$ 的比例。
  + 缺点：若物品 $j$ 为热门物品，那么它与任何物品的相似度都很高。

* 控制对热门物品的惩罚力度
  $$
  w_{i j}=\frac{|N(i) \cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
  $$

  * 参数 $\alpha$为可控惩罚力度。

* 对活跃用户的惩罚

  * 在计算物品之间的相似度时，可以进一步将用户的活跃度考虑进来。
    $$
    w_{i j}=\frac{\sum_{\operatorname{\text {u}\in N(i) \cap N(j)}} \frac{1}{\log 1+|N(u)|}}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
    $$

### 评价指标

1. 混淆矩阵
   
| **预测结果**     | **实际为正**       | **实际为负**       |
|------------------|--------------------|--------------------|
| **预测为正**     | True Positive (TP)  | False Positive (FP) |
| **预测为负**     | False Negative (FN) | True Negative (TN)  |

2. 召回率

    对用户 $u$ 推荐 $N$ 个物品记为 $R(u)$, 令用户 $u$ 在测试集上喜欢的物品集合为$T(u)$， 那么召回率定义为：

$$ \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} $$

+ 含义：在模型召回预测的物品中，预测准确的物品占用户实际喜欢的物品的比例。 

3. 精确率
精确率定义为：
$$ \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} $$ 
+ 含义：推荐的物品中，对用户准确推荐的物品占总物品的比例。 
+ 如要确保召回率高，一般是推荐更多的物品，期望推荐的物品中会涵盖用户喜爱的物品。而实际中，推荐的物品中用户实际喜爱的物品占少数，推荐的精确率就会很低。故同时要确保高召回率和精确率往往是矛盾的，所以实际中需要在二者之间进行权衡。

4. ROC曲线与AUC
   ROC曲线通过计算真正例率(TPR)和假正例率(FPR)值，然后绘制 FPR的TPR图表。ROC 曲线的左上角表示理想模型（TPR接近1，FPR 接近 0）。完全随机的模型对应于对角线（对角线上的任何点表示在某个阈值下随机猜测的模型效果。曲线越靠近左上角，说明模型性能越好。

   * True Positive Rate (TPR)
TPR（recall）表示在所有实际为正的样本中，模型正确预测为正的比例，公式为：

\[
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\]

   * False Positive Rate (FPR)
FPR 表示在所有实际为负的样本中，模型错误预测为正的比例，公式为：

\[
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
\]

AUC(曲线下面积)，0.5是一个模型预测能力的分界点。小于0.5就是在胡乱猜测。
| AUC = 0.65 | AUC = 0.93 |
|------------|------------|
| ![AUC 0.65](https://developers.google.com/static/machine-learning/crash-course/images/auc_0-65.png?hl=zh-cn) | ![AUC 0.93](https://developers.google.com/static/machine-learning/crash-course/images/auc_0-93.png?hl=zh-cn) |


5. 覆盖率
    覆盖率反映了**推荐算法发掘长尾**的能力，覆盖率越高，说明推荐算法越能将长尾中的物品推荐给用户。
$$
\text { Coverage }=\frac{\left|\bigcup_{u \in U} R(u)\right|}{|I|}
$$

+ 含义：推荐系统能够推荐出来的物品占总物品集合的比例。
  + 其中 $|I|$ 表示所有物品的个数；
  + 系统的用户集合为$U$;
  + 推荐系统给每个用户推荐一个长度为 $N$ 的物品列表$R(u)$.

+ 覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有物品都被给推荐给至少一个用户， 那么覆盖率是100%。

### 弊端
1. 泛化能力弱，无法将两个物品的相似信息推广到其他物品上，进而导致热门物品具有**很强的头部效应**，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐，也就是推荐时的同质化。
2. 需要考虑用户评分倾向，一部分用户倾向高分，一部分用户倾向低分。需要对相似度计算进行改进，否则会造成错误分类
3. 没有利用更多的用户或者物品信息，只使用交互信息进行计算，整体模型的表达能力十分有限。

## 矩阵分解

+ 原理图：
<img src="https://img-blog.csdnimg.cn/20200822212051499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />

+ 基本思想
  - 用户矩阵Q
    表示不同用户**对于不同元素的偏好程度**，取值范围[0,1]，1代表很喜欢，0代表不喜欢。
  - 物品矩阵P
    表示**每种物品含有各种元素（特征）的成分**
  - 计算：
    通过将对应向量的元素做内积运算，得到用户对该物品的喜好程度。相应的可以得到用户对每个物品的评分矩阵

+ FunkSVD with Bias 算法
  - 思想：**把求解P、Q的参数问题转换成最优化问题，通过训练集里面的观察值,利用最小化来学习用户矩阵和物品矩阵。**
  - 算法过程
  1. 在有用户矩阵和物品矩阵的前提下，若要计算用户 $u$ 对物品 $i$ 的评分， 可以根据公式：
   $$
   \operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{k=1}^{K} p_{u, k} q_{i,k}
   $$
   其中，向量 $p_u$ 表示用户 $u$ 的隐向量，向量  $q_i$ 表示物品 $i$ 的隐向量。

  2. **随机初始化**一个用户矩阵 $U$ 和一个物品矩阵 $V$，获取每个用户和物品的初始隐语义向量。一般是与`1/sqrt(F)`成正比，F为隐向量维度。

  3. 计算预测得分 with bias
   $$\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}$$.其中，$\mu$反映推荐模型整体的平均评分，一般为样本均值；$b_u$为用户偏差系数。可以使用用户 $u$ 的评分均值，也可作为训练参数；$b_i$为物品偏差系数。可以使用物品 $i$ 的得分均值，也可以当做训练参数。

  4. 对于评分矩阵中的每个元素，计算预测误差 $e_{u i}=r_{u i}-\hat{r}_{u i}$，对所有训练样本的平方误差进行累加：
   $$
   \operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)^{2}
   $$为方便后续求解，给 $SSE$ 增加系数 $1/2$ ：
     $$
     \operatorname{SSE}=\frac{1}{2} \sum_{u, i} e_{u i}^{2}=\frac{1}{2} \sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u k} q_{i k}\right)^{2}
     $$

  5.  前面提到，模型预测越准确等价于预测误差越小，那么优化的目标函数变为：
  $$
  \begin{aligned}
  \min _{q^{*}, p^{*}} \frac{1}{2} \sum_{(u, i) \in K} &\left(r_{u i}-\left(\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}\right)\right)^{2} \\
  &+\lambda\left(\left\|p_{u}\right\|^{2}+\left\|q_{i}\right\|^{2}+b_{u}^{2}+b_{i}^{2}\right)
  \end{aligned}
  $$ $K$ 表示所有用户评分样本的集合，**即评分矩阵中不为空的元素**，其他空缺值在测试时是要预测的。该目标函数需要优化的目标是用户矩阵 $U$ 和一个物品矩阵 $V$。

  6. 对于给定的目标函数，可以通过梯度下降法对参数进行优化。

   + 求解目标函数 $SSE$ 关于用户矩阵中参数 $p_{u,k}$ 的梯度：
     $$
     \frac{\partial}{\partial p_{u,k}} S S E=\frac{\partial}{\partial p_{u,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial p_{u,k}} e_{u i}=e_{u i} \frac{\partial}{\partial p_{u,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} q_{i,k}
     $$

   + 求解目标函数 $SSE$ 关于 $q_{i,k}$ 的梯度：
     $$
     \frac{\partial}{\partial q_{i,k}} S S E=\frac{\partial}{\partial q_{i,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial q_{i,k}} e_{u i}=e_{u i} \frac{\partial}{\partial q_{i,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} p_{u,k}
     $$

  7. 参数梯度更新
   $$
   p_{u, k}=p_{u,k}-\eta (-e_{ui}q_{i, k})=p_{u,k}+\eta e_{ui}q_{i, k} \\ 
   q_{i, k}=q_{i,k}-\eta (-e_{ui}p_{u,k})=q_{i, k}+\eta e_{ui}p_{u, k}\\
   \frac{\partial}{\partial b_{i}} S S E=-e_{u i}+\lambda b_{i}\\
   \frac{\partial}{\partial b_{u}} S S E=-e_{u i} +\lambda b_{u}
   $$ 其中，$\eta$ 表示学习率，用于控制步长。当**参数很多**的时候，就是两个矩阵很大的时候，往往容易陷入**过拟合**的困境，需要在目标函数上面加上正则化的损失。

  - 原理图，==分解出的k维特征是模型待学习的参数==
<div align=center>
<img src="https://img-blog.csdnimg.cn/20200823101513233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:70%;" />
</div>

## FM模型（分解机）
**主要是思想**
+ 优化函数
$$
y = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n}\sum_{i+1}^n\lt v_i,v_j\gt x_ix_j
$$ 改进思想就是**为每个$x_i$计算一个embedding，然后将两个向量之间的embedding做内积得到之前所谓的$w_{ij}$**.这使得即使两个特征之前从未在训练集中**同时**出现，只需要$x_i$和其他的$x_k$同时出现过就可以计算出$x_i$的embedding，大大提升了模型的泛化能力。**当交叉项参数$w_{ij}$全为0的时候，整个模型就退化为普通的LR模型**。

上面的公式中： 

- $\omega_{0}$为**全局偏置**；
- $\omega_{i}$是模型第$i$个变量的权重;
- $\omega_{ij} = < v_{i}, v_{j}>$特征$i$和$j$的交叉权重;
- $v_{i} $是第$i$维特征的隐向量;
- $<\cdot, \cdot>$代表向量点积;
- $k(k<<n)$为隐向量的长度，包含 $k$ 个描述特征的因子。

**降低时间复杂度的证明**：
$\sum$运算是线性的，可以互换位置。
$$
\begin{align} \sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{<v_i,v_j>x_ix_j}}
&= \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{<v_i,v_j>x_ix_j}} - \frac{1}{2} {\sum_{i=1}^{n}{<v_i,v_i>x_ix_i}} \\
&= \frac{1}{2} \left( \sum_{i=1}^{n}{\sum_{j=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \sum_{i=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \right) \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right) \cdot \left( \sum_{j=1}^{n}{v_{j,f}x_j} \right) - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right)^2 - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \end{align}
$$
**解释**：

- $v_{i,f}$ 是一个具体的值；
- 第1个等号：对称矩阵 $W$ 对角线上半部分；
- 第2个等号：把向量内积 $v_{i}$,$v_{j}$ 展开成累加和的形式；
- 第3个等号：提出公共部分；
- 第4个等号： $i$ 和 $j$ 相当于是一样的，表示成平方过程。

## LGBT + LR
+ 思想
  利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当做LR模型的输入，来产生最后的预测结果，该模型能够综合利用用户、物品和上下文等多种不同的特征，生成较为全面的推荐结果。
+ GBDT模型
  GBDT是通过采用加法模型(即基函数的线性组合），以及不断减小训练过程产生的误差来达到将数据分类或者回归的算法， 其训练过程如下：

  <div align=center>
  <img src="https://img-blog.csdnimg.cn/20200908202508786.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" style="zoom:65%;" />    
  </div>
  gbdt通过多轮迭代，每轮迭代会产生一个弱分类器，每个分类器**在上一轮分类器的残差基础上进行训练**。 gbdt对弱分类器的要求一般是足够简单，并且低方差高偏差。因为训练的过程是通过降低偏差来不断提高最终分类器的精度。由于上述高偏差和简单的要求，每个分类回归树的深度不会很深。最终的总分类器是将每轮训练得到的弱分类器加权求和得到的（也就是加法模型）。  
  GBDT 来解决二分类问题和解决回归问题的本质是一样的，都是通过不断构建决策树的方式，使预测结果一步步的接近目标值，但是二分类问题和回归问题的损失函数是不同的，回归问题中一般使用的是平方损失，而二分类问题中，GBDT和逻辑回归一样，使用的下面这个：

  $$
  L=\arg \min \left[\sum_{i}^{n}-\left(y_{i} \log \left(p_{i}\right)+\left(1-y_{i}\right) \log \left(1-p_{i}\right)\right)\right]
  $$
  其中， $y_i$是第$i$个样本的观测值， 取值要么是0要么是1， 而$p_i$是第$i$个样本的预测值， 取值是0-1之间的概率，由于知道GBDT拟合的残差是当前模型的负梯度， 那么需要求出这个模型的导数，即$\frac{dL}{dp_i}$，对于某个特定的样本，求导的话就可以只考虑它本身，去掉加和号，那么就变成了$\frac{dl}{dp_i}$，其中$l$如下：
  $$
  \begin{aligned}
  l &=-y_{i} \log \left(p_{i}\right)-\left(1-y_{i}\right) \log \left(1-p_{i}\right) \\
  &=-y_{i} \log \left(p_{i}\right)-\log \left(1-p_{i}\right)+y_{i} \log \left(1-p_{i}\right) \\
  &=-y_{i}\left(\log \left(\frac{p_{i}}{1-p_{i}}\right)\right)-\log \left(1-p_{i}\right)
  \end{aligned}
  $$
  根据逻辑回归，$\left(\log \left(\frac{p_{i}}{1-p_{i}}\right)\right)$就是对几率比取了个对数，并且在逻辑回归里面这个式子等于$\theta X$,所以才推出了$p_i=\frac{1}{1+e^-{\theta X}}$的那个形式。这里令$\eta_i=\frac{p_i}{1-p_i}$, 即$p_i=\frac{\eta_i}{1+\eta_i}$, 则上面这个式子变成了：
  $$
  \begin{aligned}
  l &=-y_{i} \log \left(\eta_{i}\right)-\log \left(1-\frac{e^{\log \left(\eta_{i}\right)}}{1+e^{\log \left(\eta_{i}\right)}}\right) \\
  &=-y_{i} \log \left(\eta_{i}\right)-\log \left(\frac{1}{1+e^{\log \left(\eta_{i}\right)}}\right) \\
  &=-y_{i} \log \left(\eta_{i}\right)+\log \left(1+e^{\log \left(\eta_{i}\right)}\right)
  \end{aligned}
  $$
 对$log(\eta_i)$求导， 得

  $$
  \frac{d l}{d \log (\eta_i)}=-y_{i}+\frac{e^{\log \left(\eta_{i}\right)}}{1+e^{\log \left(\eta_{i}\right)}}=-y_i+p_i
  $$

  这样， 就得到了某个训练样本在当前模型的梯度值，那么残差就是$y_i-p_i$。GBDT二分类的这个思想，其实和逻辑回归的思想一样，**逻辑回归是用一个线性模型去拟合$P(y=1|x)$这个事件的对数几率$log\frac{p}{1-p}=\theta^Tx$**， GBDT二分类也是如此，用一系列的梯度提升树去拟合这个对数几率，其分类模型可以表达为：

  $$
  P(Y=1 \mid x)=\frac{1}{1+e^{-F_{M}(x)}}
  $$

  下面具体来看GBDT的生成过程， 构建分类GBDT的步骤有两个：
    1. 初始化GBDT
    和回归问题一样，分类 GBDT 的初始状态也只有一个叶子节点，该节点为所有样本的初始预测值，如下：
$$
F_{0}(x)=\arg \min _{\gamma} \sum_{i=1}^{n} L(y, \gamma)
$$

  	上式 $F$代表GBDT模型，$F_0$是模型的初识状态，该式子的意思是找到一个$\gamma$，使所有样本的 Loss 最小，在这里及下文中，$\gamma$都表示节点的输出，即叶子节点，且它是一个 $log(\eta_i)$ 形式的值(回归值)，在初始状态，$\gamma =F_0$。
  示例：
    <div align=center>
    <img src="https://img-blog.csdnimg.cn/20200910095539432.png#pic_center" alt="在这里插入图片描述" style="zoom:80%;" /> 
    </div>

 	希望构建 GBDT 分类树，它能通过「喜欢爆米花」、「年龄」和「颜色偏好」这 3 个特征来预测某一个样本是否喜欢看电影。把数据代入上面的公式中求Loss:
    $$
    \operatorname{Loss}=L(1, \gamma)+L(1, \gamma)+L(0, \gamma)
    $$
  		为了令其最小，求导让导数为0，则：
    $$
    \operatorname{Loss}=p-1 + p-1+p=0
    $$
 		 于是， 就得到了初始值$p=\frac{2}{3}=0.67, \gamma=log(\frac{p}{1-p})=0.69$, 模型的初识状态$F_0(x)=0.69$

    2. 循环生成决策树
    这里回忆一下回归树的生成步骤，其实有4小步，第一就是计算负梯度值得到残差，第二步是用回归树拟合残差，第三步是计算叶子节点的输出值，第四步是更新模型。 
        1. 计算负梯度得到残差
         $$
         r_{i m}=-\left[\frac{\partial L\left(y_{i}, F\left(x_{i}\right)\right)}{\partial F\left(x_{i}\right)}\right]_{F(x)=F_{m-1}(x)}
         $$
         此处使用$m-1$棵树的模型， 计算每个样本的残差$r_{im}$, 就是上面的$y_i-pi$, 于是例子中， 每个样本的残差：
         <div align=center>
         <img src="https://img-blog.csdnimg.cn/20200910101154282.png#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />
         </div>
    
         2. 使用回归树来拟合$r_{im}$， 这里的$i$表示样本，简单的说就是遍历每个特征，每个特征下遍历每个取值，计算分裂后两组数据的平方损失，找到最小的那个划分节点。 假如我们产生的第2棵决策树如下：
    
         <div align=center>
         <img src="https://img-blog.csdnimg.cn/20200910101558282.png#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />
         </div>
    
         3. 对于每个叶子节点$j$, 计算最佳残差拟合值
         $$
         \gamma_{j m}=\arg \min _{\gamma} \sum_{x \in R_{i j}} L\left(y_{i}, F_{m-1}\left(x_{i}\right)+\gamma\right)
         $$
         意思是，在刚构建的树$m$中，找到每个节点$j$的输出$\gamma_{jm}$, 能使得该节点的loss最小。看一下这个$\gamma$的求解方式.首先，把损失函数写出来，对于左边的第一个样本，有
         $$
         L\left(y_{1}, F_{m-1}\left(x_{1}\right)+\gamma\right)=-y_{1}\left(F_{m-1}\left(x_{1}\right)+\gamma\right)+\log \left(1+e^{F_{m-1}\left(x_{1}\right)+\gamma}\right)
         $$
         这个式子就是上面推导的$l$，因为要用回归树做分类，所以这里把分类的预测概率转换成了对数几率回归的形式，即$log(\eta_i)$，这个就是模型的回归输出值。而如果求这个损失的最小值要，求导解出令损失最小的$\gamma$。但是上面这个式子求导会很麻烦，所以这里介绍了一个技巧就是**使用二阶泰勒公式来近似表示该式，再求导**
         $$
         f(x+\Delta x) \approx f(x)+\Delta x f^{\prime}(x)+\frac{1}{2} \Delta x^{2} f^{\prime \prime}(x)+O(\Delta x)
         $$
         这里就相当于把$L(y_1, F_{m-1}(x_1))$当做常量$f(x)$， $\gamma$作为变量$\Delta x$， 将$f(x)$二阶展开：
         $$
         L\left(y_{1}, F_{m-1}\left(x_{1}\right)+\gamma\right) \approx L\left(y_{1}, F_{m-1}\left(x_{1}\right)\right)+L^{\prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right) \gamma+\frac{1}{2} L^{\prime \prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right) \gamma^{2}
         $$
         这时候再求导就简单了
         $$
         \frac{d L}{d \gamma}=L^{\prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right)+L^{\prime \prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right) \gamma
         $$
         Loss最小的时候， 上面的式子等于0， 就可以得到$\gamma$:
         $$
         \gamma_{11}=\frac{-L^{\prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right)}{L^{\prime \prime}\left(y_{1}, F_{m-1}\left(x_{1}\right)\right)}
         $$
         **因为分子就是残差(上述已经求到了)， 分母可以通过对残差求导，得到原损失函数的二阶导：**
         $$
         \begin{aligned}
         L^{\prime \prime}\left(y_{1}, F(x)\right) &=\frac{d L^{\prime}}{d \log (\eta_1)} \\
         &=\frac{d}{d \log (\eta_1)}\left[-y_{i}+\frac{e^{\log (\eta_1)}}{1+e^{\log (\eta_1)}}\right] \\
         &=\frac{d}{d \log (\eta_1)}\left[e^{\log (\eta_1)}\left(1+e^{\log (\eta_1)}\right)^{-1}\right] \\
         &=e^{\log (\eta_1)}\left(1+e^{\log (\eta_1)}\right)^{-1}-e^{2 \log (\eta_1)}\left(1+e^{\log (\eta_1)}\right)^{-2} \\
         &=\frac{e^{\log (\eta_1)}}{\left(1+e^{\log (\eta_1)}\right)^{2}} \\
         &=\frac{\eta_1}{(1+\eta_1)}\frac{1}{(1+\eta_1)} \\
         &=p_1(1-p_1)
         \end{aligned}
         $$
         这时候， 就可以算出该节点的输出：
         $$
         \gamma_{11}=\frac{r_{11}}{p_{10}\left(1-p_{10}\right)}=\frac{0.33}{0.67 \times 0.33}=1.49
         $$
         这里的下面$\gamma_{jm}$表示第$m$棵树的第$j$个叶子节点。 接下来是右边节点的输出， 包含样本2和样本3， 同样使用二阶泰勒公式展开：
         $$
         \begin{array}{l}
         L\left(y_{2}, F_{m-1}\left(x_{2}\right)+\gamma\right)+L\left(y_{3}, F_{m-1}\left(x_{3}\right)+\gamma\right) \\
         \approx L\left(y_{2}, F_{m-1}\left(x_{2}\right)\right)+L^{\prime}\left(y_{2}, F_{m-1}\left(x_{2}\right)\right) \gamma+\frac{1}{2} L^{\prime \prime}\left(y_{2}, F_{m-1}\left(x_{2}\right)\right) \gamma^{2} \\
         +L\left(y_{3}, F_{m-1}\left(x_{3}\right)\right)+L^{\prime}\left(y_{3}, F_{m-1}\left(x_{3}\right)\right) \gamma+\frac{1}{2} L^{\prime \prime}\left(y_{3}, F_{m-1}\left(x_{3}\right)\right) \gamma^{2}
         \end{array}
         $$
         求导， 令其结果为0，就会得到， 第1棵树的第2个叶子节点的输出：
         $$
         \begin{aligned}
         \gamma_{21} &=\frac{-L^{\prime}\left(y_{2}, F_{m-1}\left(x_{2}\right)\right)-L^{\prime}\left(y_{3}, F_{m-1}\left(x_{3}\right)\right)}{L^{\prime \prime}\left(y_{2}, F_{m-1}\left(x_{2}\right)\right)+L^{\prime \prime}\left(y_{3}, F_{m-1}\left(x_{3}\right)\right)} \\
         &=\frac{r_{21}+r_{31}}{p_{20}\left(1-p_{20}\right)+p_{30}\left(1-p_{30}\right)} \\
         &=\frac{0.33-0.67}{0.67 \times 0.33+0.67 \times 0.33} \\
         &=-0.77
         \end{aligned}
         $$
         可以看出， 对于任意叶子节点， 我们可以直接计算其输出值：
         $$
         \gamma_{j m}=\frac{\sum_{i=1}^{R_{i j}} r_{i m}}{\sum_{i=1}^{R_{i j}} p_{i, m-1}\left(1-p_{i, m-1}\right)}
         $$
    
          4. 更新模型$F_m(x)$
         $$
         F_{m}(x)=F_{m-1}(x)+\nu \sum_{j=1}^{J_{m}} \gamma_{m}
         $$
    
    这样， 通过多次循环迭代， 就可以得到一个比较强的学习器$F_m(x)$
    
+ GDBT + LR
  + 基本结构
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/20200910161923481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:67%;" />    
  </div>
  训练时，GBDT 建树的过程相当于自动进行的特征组合和离散化，然后从根结点到叶子节点的这条路径就可以看成是不同特征进行的特征组合，用叶子节点可以唯一的表示这条路径，并作为一个离散特征传入 LR 进行**二次训练**。

+ 注意点
  1. **通过GBDT进行特征组合之后得到的==离散向量和训练数据的原特征一块==作为逻辑回归的输入，而不仅仅全是这种离散特征**
  2. 建树的时候用ensemble建树的原因就是一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少棵树。
  3. RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。
  4. 在CRT预估中，GBDT一般会建立两类树(非ID特征建一类， ID类特征建一类)，AD，ID类特征在CTR预估中是非常重要的特征，直接将AD，ID作为feature进行建树不可行，需要为每个AD，ID建GBDT树。
   
# 深度学习方法
==重点是模型结构以及设计思想，并没有在数据上过多深究==

## Neural Collaborative Filtering (NeuralCF)

### 模型结构
<div align="center">
  <img src="https://static001.geekbang.org/resource/image/5f/2c/5ff301f11e686eedbacd69dee184312c.jpg" alt="NeuralCF Model" style="zoom:33%;">
</div>

### 原理
- **输入特征**：用户ID和项目ID转换为OneHot向量，并映射成指定维度的稠密向量，解决冷启动问题。
- **GMF（广义矩阵分解部分）**：用户与物品特征矩阵逐元素点积，通过线性方法学习特征。
- **MLP**：设置用户和物品的MLP，通过特征组合拼接embedding，经过线性层得到MLP的输出。
- **最终输出**：拼接GMF与MLP特征，通过线性层得到最终输出。

### 回归方法：均方误差
$$
L_{sqr}=\sum_{(u,i)\in y\cup y^-}w_{ui}(y_{ui}-\hat{y}_{ui})^2
$$
其中 $w_{ui}$ 为超参数，给每个样本赋权重。

### 似然函数
$$
p(y,y^-|P,Q,\Theta_f)=\prod_{(u,i)\in{y}}\hat{y}_{ui}\prod_{(u,j)\in{y^-}}(1-\hat{y}_{uj})
$$

### 目标函数：对似然函数取负对数
$$
L=-\sum_{(u,i)\in{y}}log\hat{y}_{ui}-\sum_{(u,j)\in{y^-}}log(1-\hat{y}_{uj})=-\sum_{(u,i)\in{y}\cup{y}^-}y_{ui}log \hat{y}_{ui}+(1-y_{ui})log(1-\hat{y}_{ui})
$$
使用随机梯度下降（SGD）进行训练优化。这个函数等价于交叉熵损失函数(binary cross-entropy loss)。通过对NCF进行概率处理，将隐性反馈的推荐问题当做二分类问题来解决。对于负样本 $y^-$，每次迭代均匀地从未观察到交互作用中采样作为负样本，控制采样比例。

**注**：MF是NCF模型的一个特例。

---

## DeepCrossing

**简介**：第一个完整解决特征工程、稀疏向量稠密化、和多层神经网络优化的推荐系统深度学习应用，主要用于点击率预测。

### 模型结构
<div align="center">
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片2020100916594542.png" alt="DeepCrossing Model" style="zoom:67%;">
</div>

### 模型原理
- **需解决问题**：
  1. 离散特征编码后过于稀疏，影响神经网络训练。
  2. 特征的自动交叉组合。
  3. 输出层达成优化目标。

- **各层作用**：
  1. **Embedding Layer**：将离散变量转换为OneHot变量，并转换为稠密向量。
  2. **Stacking Layer**：拼接数值型特征和Embedding作为模型输入。
  3. **MLP + Residual Connection**：两层MLP进行特征非线性变换，并与原始输入特征残差连接，最后线性层+激活函数得到预测。

---

## Product Neural Network (PNN)

**工程应用**：通常仅用IPNN（Inner Product Neural Network）。

### 模型结构
<div align="center">
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210308142624189.png" alt="PNN Model" style="zoom:50%;">
</div>

### 原理
- **线性模块**：将所有特征拼接在一起，论文中使用1进行线性变换。
- **非线性模块**：初始化参数矩阵表示特征，使用内积操作得到特征表示。公式如下：

$$
g(f_i,f_j) = <f_i, f_j>
$$

 计算公式：
$$
l_p^n = \sum_{i=1}^N \sum_{j=1}^N (W_p^n)_{i,j} \langle f_i, f_j \rangle
$$
优化后的公式：
$$
l_p = (||\sum_{i=1}^N \theta^1 f_i||^2, ||\sum_{i=1}^N \theta^2 f_i||^2, ..., ||\sum_{i=1}^N \theta^{D_1} f_i||^2)
$$

---

## Wide & Deep

**特性**：Wide部分有助于模型记忆，Deep部分有助于泛化，适合探索新特征组合。
**缺点**： Wide部分的特征组合需要建立在大量工程经验的基础上，极大的依赖人工处理。

### 模型结构
<div align="center">
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/Javaimage-20200910214310877.png" alt="Wide & Deep Model" style="zoom:65%;">
</div>

### 模型原理
- **Wide部分**：广义线性模型，包含原始特征和交叉特征，使用L1正则的FTRL优化，确保Wide部分稀疏化。
- **Deep部分**：DNN模型，包含数值特征和类别特征（需Embedding后输入DNN），通过非线性变换提高模型泛化能力。

**Wide与Deep结合**：通过逻辑回归联合训练Wide和Deep的输出，优化器使用FTRL（Wide部分）和Adagrad（Deep部分）：
$$
P(Y=1|x)=\delta(w_{wide}^T[x,\phi(x)] + w_{deep}^T a^{(lf)} + b)
$$

## DeepFM

### 模型结构
<div align = center>
<img src="https://i-blog.csdnimg.cn/blog_migrate/90a21d85810a74600f340be652d209b2.png#pic_center" style="zoom:50%;" />
</div>

### 模型原理
- **FM层**：这个在推荐系统中的地位非常高，需要重点关注。实际上就是一阶特征和二阶特征拼接之后经过sigmoid激活函数得到logits。
$$
\hat{y}_{FM}(x) = w_0+\sum_{i=1}^N w_ix_i + \sum_{i=1}^N \sum_{j=i+1}^N v_i^T v_j x_ix_j
$$
具体的结构如下：
<div align = center>
<img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210225181340313.png" alt="image-20210225181340313" style="zoom: 67%;" />
</div>
- **Deep**：
结构图：
<div align = center>
<img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210225181010107.png" alt="image-20210225181010107" style="zoom:50%;" />
</div>
用来学习高阶的特征组合，也就是使用MLP对拼接后的稠密特征进行处理。

## NFM

### DeepFM上的改进思路
1. 改进思路->**用一个表达能力更强的函数来替代原FM中二阶隐向量内积的部分**，因为原本的二阶交叉是一个线性模型，非常局限。这里作者考虑将线性内积改变为神经网络进行特征交叉。
2. 计算公式
$$
\hat{y}_{N F M}(\mathbf{x})=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+f(\mathbf{x})
$$
### 模型结构
1. 结构
<div align = center>
<img src = 'https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2f40bbac85124a7db8e0c9bc3a3b2072~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp' style="zoom:80%;" />
</div>

2. 输入层
   和之前处理一样，先onehot再稠密embedding

3. 特征交叉池化层
   实现了FM与DNN的无缝连接， 组成了一个大的网络，且能够正常的反向传播。假设$\mathcal{V}_{x}$是所有特征embedding的集合，在特征交叉池化层的操作：

  $$
  f_{B I}\left(\mathcal{V}_{x}\right)=\sum_{i=1}^{n} \sum_{j=i+1}^{n} x_{i} \mathbf{v}_{i} \odot x_{j} \mathbf{v}_{j}
  $$

  $\odot$表示两个向量的元素积操作，即两个向量对应维度相乘得到的元素积向量（不是点乘），其中第$k$维的操作：
  $$
  \left(v_{i} \odot v_{j}\right)_{k}=\boldsymbol{v}_{i k} \boldsymbol{v}_{j k}
  $$

  这便定义了在embedding空间特征的二阶交互，这个不仔细看会和感觉FM的最后一项很像，但是不一样，一定要注意这个地方不是两个隐向量的内积，而是**元素积(逐元素相乘)**，也就是这一个交叉完了之后**k个维度不求和**，最后会得到一个$k$维向量。在进行两两Embedding元素积之后，对交叉特征向量取和，得到该层的输出向量，很显然，输出是一个$k$维的向量。这里不求和的原因是因为**原本的FM里面的求和操作是一个线性操作，这会使得模型对特征的学习程度不够，作者想使用非线性的方法去综合特征，在这里就是使用深度学习方法做非线性特征变换**

  这里很大的一点改进就是加入特征池化层之后，把二阶交互的信息合并，且上面接了一个DNN网络，这样就能够增强FM的表达能力了，因为FM只能到二阶，而这里的DNN可以进行多阶且非线性，只要FM把二阶的学习好了，DNN这块学习来会更加容易， 作者在论文中也说明了这一点，且通过后面的实验证实了这个观点。

  如果不加DNN，NFM就退化成了FM，所以改进的关键就在于加了一个这样的层，组合了一下二阶交叉的信息，然后又给了DNN进行高阶交叉的学习，成了一种“加强版”的FM。

  Bi-Interaction层不需要额外的模型学习参数，更重要的是它在一个线性的时间内完成计算，和FM一致的，即时间复杂度为$O\left(k N_{x}\right)$，$N_x$为embedding向量的数量。参考FM，可以将上式转化为：
  $$
  f_{B I}\left(\mathcal{V}_{x}\right)=\frac{1}{2}\left[\left(\sum_{i=1}^{n} x_{i} \mathbf{v}_{i}\right)^{2}-\sum_{i=1}^{n}\left(x_{i} \mathbf{v}_{i}\right)^{2}\right]
  $$
  后面代码复现NFM就是用的这个公式直接计算，比较简便且清晰。可以看到与FM的差异就是少了一个对embedding维度求和的部分。
  
4. 隐藏层
  这一层就是全连接的神经网络， DNN在进行特征的高层非线性交互上有着天然的学习优势，公式如下：
  $$
  \begin{aligned} 
  \mathbf{z}_{1}=&\sigma_{1}\left(\mathbf{W}_{1} f_{B I} 
  \left(\mathcal{V}_{x}\right)+\mathbf{b}_{1}\right)  \\
  \mathbf{z}_{2}=& \sigma_{2}\left(\mathbf{W}_{2} \mathbf{z}_{1}+\mathbf{b}_{2}\right) \\
  \ldots \ldots \\
  \mathbf{z}_{L}=& \sigma_{L}\left(\mathbf{W}_{L} \mathbf{z}_{L-1}+\mathbf{b}_{L}\right)
  \end{aligned}
  $$
  这里的$\sigma_i$是第$i$层的激活函数。

5. 预测层

这个就是最后一层的结果直接过一个隐藏层，但注意由于这里是回归问题，没有加sigmoid激活：
$$
f(\mathbf{x})=\mathbf{h}^{T} \mathbf{z}_{L}
$$

所以， NFM模型的前向传播过程总结如下：
$$
\begin{aligned}
\hat{y}_{N F M}(\mathbf{x}) &=w_{0}+\sum_{i=1}^{n} w_{i} x_{i} \\
&+\mathbf{h}^{T} \sigma_{L}\left(\mathbf{W}_{L}\left(\ldots \sigma_{1}\left(\mathbf{W}_{1} f_{B I}\left(\mathcal{V}_{x}\right)+\mathbf{b}_{1}\right) \ldots\right)+\mathbf{b}_{L}\right)
\end{aligned}
$$

### 创新点

特征交叉池化层，基于它，实现了FM和DNN的无缝连接，使得DNN可以在底层就学习到包含更多信息的组合特征，这时候，就会减少DNN的很多负担，只需要很少的隐藏层就可以学习到高阶特征信息。NFM相比之前的DNN， 

## DCN
**改进：使用Cross Network替换掉了Wide部分，来自动进行特征之间的交叉，并且网络的时间和空间复杂度都是线性的。**
### 模型结构
<div align = center>
<img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片dcn.png" style="zoom:67%;" />
</div>
### Embedding和Stacking 层
这里的作用依然是把稀疏离散的类别型特征变成低维密集型。
$$
\mathbf{x}_{\text {embed, } i}=W_{\text {embed, } i} \mathbf{x}_{i}
$$
其中对于某一类稀疏分类特征（如id），$X_{embed, i}$是第个$i$分类值（id序号）的embedding向量。$W_{embed,i}$是embedding矩阵， $n_e\times n_v$维度， $n_e$是embedding维度， $n_v$是该类特征的唯一取值个数。$x_i$属于该特征的二元稀疏向量(one-hot)编码的。**实质上就是在训练得到的Embedding参数矩阵中找到属于当前样本对应的Embedding向量**。

最后，该层需要将所有的密集型特征与通过embedding转换后的特征进行联合（Stacking）：
$$
\mathbf{x}_{0}=\left[\mathbf{x}_{\text {embed, } 1}^{T}, \ldots, \mathbf{x}_{\text {embed, }, k}^{T}, \mathbf{x}_{\text {dense }}^{T}\right]
$$
一共$k$个类别特征， dense是数值型特征， 两者在特征维度拼在一块。 

### Cross Network
设计该网络的目的是增加特征之间的交互力度。交叉网络由多个交叉层组成， 假设第$l$层的输出向量$x_l$， 那么对于第$l+1$层的输出向量$x_{l+1}$表示为：

$$
\mathbf{x}_{l+1}=\mathbf{x}_{0} \mathbf{x}_{l}^{T} \mathbf{w}_{l}+\mathbf{b}_{l}+\mathbf{x}_{l}=f\left(\mathbf{x}_{l}, \mathbf{w}_{l}, \mathbf{b}_{l}\right)+\mathbf{x}_{l}
$$
可以看到， 交叉层的二阶部分非常类似PNN提到的外积操作， 在此基础上增加了外积操作的权重向量$w_l$， 以及原输入向量$x_l$和偏置向量$b_l$。 交叉层的可视化如下：

<img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片cross.png" style="zoom:67%;" />

可以看到， 每一层增加了一个$n$维的权重向量$w_l$（n表示输入向量维度）， 并且在每一层均保留了输入向量， 因此输入和输出之间的变化不会特别明显。关于这一层， 原论文里面有个具体的证明推导Cross Network为啥有效， 不过比较复杂，这里我拿一个式子简单的解释下上面这个公式的伟大之处：

> **我们根据上面这个公式， 尝试的写前面几层看看:**
>
> $l=0:\mathbf{x}_{1} =\mathbf{x}_{0} \mathbf{x}_{0}^{T} \mathbf{w}_{0}+ \mathbf{b}_{0}+\mathbf{x}_{0}$
>
> $l=1:\mathbf{x}_{2} =\mathbf{x}_{0} \mathbf{x}_{1}^{T} \mathbf{w}_{1}+ \mathbf{b}_{1}+\mathbf{x}_{1}=\mathbf{x}_{0} [\mathbf{x}_{0} \mathbf{x}_{0}^{T} \mathbf{w}_{0}+ \mathbf{b}_{0}+\mathbf{x}_{0}]^{T}\mathbf{w}_{1}+\mathbf{b}_{1}+\mathbf{x}_{1}$
>
> $l=2:\mathbf{x}_{3} =\mathbf{x}_{0} \mathbf{x}_{2}^{T} \mathbf{w}_{2}+ \mathbf{b}_{2}+\mathbf{x}_{2}=\mathbf{x}_{0} [\mathbf{x}_{0} [\mathbf{x}_{0} \mathbf{x}_{0}^{T} \mathbf{w}_{0}+ \mathbf{b}_{0}+\mathbf{x}_{0}]^{T}\mathbf{w}_{1}+\mathbf{b}_{1}+\mathbf{x}_{1}]^{T}\mathbf{w}_{2}+\mathbf{b}_{2}+\mathbf{x}_{2}$

我们暂且写到第3层的计算， 我们会发现什么结论呢？  给大家总结一下：

1. $\mathrm{x}_1$中包含了所有的$\mathrm{x}_0$的1,2阶特征的交互， $\mathrm{x}_2$包含了所有的$\mathrm{x}_1, \mathrm{x}_0$的1、2、3阶特征的交互，$\mathrm{x}_3$中包含了所有的$\mathrm{x}_2$, $\mathrm{x}_1$与$\mathrm{x}_0$的交互，$\mathrm{x}_0$的1、2、3、4阶特征交互。 因此， 交叉网络层的叉乘阶数是有限的。 **第$l$层特征对应的最高的叉乘阶数$l+1$**

2. Cross网络的参数是共享的， 每一层的这个权重特征之间共享， 这个可以使得模型泛化到看不见的特征交互作用， 并且对噪声更具有鲁棒性。 例如两个稀疏的特征$x_i,x_j$， 它们在数据中几乎不发生交互， 那么学习$x_i,x_j$的权重对于预测没有任何的意义。

3. 计算交叉网络的参数数量。 假设交叉层的数量是$L_c$， 特征$x$的维度是$n$， 那么总共的参数是：

   $$
   n\times L_c \times 2
   $$
   这个就是每一层会有$w$和$b$。且$w$维度和$x$的维度是一致的。

4. 交叉网络的时间和空间复杂度是线性的。这是因为， 每一层都只有$w$和$b$， 没有激活函数的存在，相对于深度学习网络， 交叉网络的复杂性可以忽略不计。

5. Cross网络是FM的泛化形式， 在FM模型中， 特征$x_i$的权重$v_i$， 那么交叉项$x_i,x_j$的权重为$<x_i,x_j>$。在DCN中， $x_i$的权重为${W_K^{(i)}}_{k=1}^l$, 交叉项$x_i,x_j$的权重是参数${W_K^{(i)}}_{k=1}^l$和${W_K^{(j)}}_{k=1}^l$的乘积，这个看上面那个例子展开感受下。因此两个模型都各自学习了独立于其他特征的一些参数，并且交叉项的权重是相应参数的某种组合。FM只局限于2阶的特征交叉(一般)，而DCN可以构建更高阶的特征交互， 阶数由网络深度决定，并且交叉网络的参数只依据输入的维度线性增长。

6. 还有一点我们也要了解，对于每一层的计算中， 都会跟着$\mathrm{x}_0$, 这个是咱们的原始输入， 之所以会乘以一个这个，是为了保证后面不管怎么交叉，都不能偏离我们的原始输入太远，别最后交叉交叉都跑偏了。

7. $\mathbf{x}_{l+1}=f\left(\mathbf{x}_{l}, \mathbf{w}_{l}, \mathbf{b}_{l}\right)+\mathbf{x}_{l}$, 这个东西其实有点跳远连接的意思，也就是和ResNet也有点相似，无形之中还能有效的缓解梯度消失现象。

### 组合输出层
这个层负责将两个网络的输出进行拼接， 并且通过简单的Logistics回归完成最后的预测：
$$
p=\sigma\left(\left[\mathbf{x}_{L_{1}}^{T}, \mathbf{h}_{L_{2}}^{T}\right] \mathbf{w}_{\text {logits }}\right)
$$
其中$\mathbf{x}_{L_{1}}^{T}$$\mathbf{h}_{L_{2}}^{T}$表示交叉网络和深度网络的输出。
最后二分类的损失函数依然是交叉熵损失：
$$
\text { loss }=-\frac{1}{N} \sum_{i=1}^{N} y_{i} \log \left(p_{i}\right)+\left(1-y_{i}\right) \log \left(1-p_{i}\right)+\lambda \sum_{l}\left\|\mathbf{w}_{i}\right\|^{2}
$$