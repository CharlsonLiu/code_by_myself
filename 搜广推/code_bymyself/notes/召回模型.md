# 基于协同过滤的召回
## Use-CF & Item-CF

**示例图片**
![image-20210629232622758](http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210629232622758.png)

### user

**计算过程**
1. 计算用户之间的相似度

   + 根据几种评价指标,计算出各用户之间的相似程度。对于用户 Alice，选取出与其最相近的 $N$ 个用户。

2. 计算用户对新物品的评分预测

   + 方法一：利用目标用户与相似用户之间的相似度以及相似用户对物品的评分，来预测目标用户对候选物品的评分估计：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot R_{\mathrm{s}, \mathrm{p}}\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，权重 $w_{u,s}$ 是用户 $u$ 和用户 $s$ 的相似度， $R_{s,p}$ 是用户 $s$ 对物品 $p$ 的评分。

   + 方法二：考虑到用户评分的偏置，即有的用户喜欢打高分， 有的用户喜欢打低分的情况。公式如下：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\bar{R}_{u} + \frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot \left(R_{s, p}-\bar{R}_{s}\right)\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，$\bar{R}_{s}$ 表示用户 $s$ 对物品的历史平均评分。

3. 对用户进行物品推荐

   + 在获得用户 $u$ 对不同物品的评价预测后， 最终的推荐列表根据预测评分进行排序得到。 

### item

计算过程
1. 计算物品之间的相似度：余弦相似性或者皮尔逊相关系数。选取TopN相似物品计算评分
2. 根据选取出来的TopN，与user的计算方式相同，计算得分。

由于物品推荐存在长尾效应，需要对推荐权重进行控制，以防止推荐内容过于同质化。

* base 公式
  $$
  w_{i j}=\frac{|N(i) \bigcap N(j)|}{|N(i)|}
  $$

  + 该公式表示同时喜好物品 $i$ 和物品 $j$ 的用户数，占喜爱物品 $i$ 的比例。
  + 缺点：若物品 $j$ 为热门物品，那么它与任何物品的相似度都很高。

* 控制对热门物品的惩罚力度
  $$
  w_{i j}=\frac{|N(i) \cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
  $$

  * 参数 $\alpha$为可控惩罚力度。

* 对活跃用户的惩罚

  * 在计算物品之间的相似度时，可以进一步将用户的活跃度考虑进来。
    $$
    w_{i j}=\frac{\sum_{\operatorname{\text {u}\in N(i) \cap N(j)}} \frac{1}{\log 1+|N(u)|}}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
    $$

### 弊端
1. 泛化能力弱，无法将两个物品的相似信息推广到其他物品上，进而导致热门物品具有**很强的头部效应**，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐，也就是推荐时的同质化。
2. 需要考虑用户评分倾向，一部分用户倾向高分，一部分用户倾向低分。需要对相似度计算进行改进，否则会造成错误分类
3. 没有利用更多的用户或者物品信息，只使用交互信息进行计算，整体模型的表达能力十分有限。

## 矩阵分解

+ 原理图：
<img src="https://img-blog.csdnimg.cn/20200822212051499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />

+ 基本思想
  - 用户矩阵Q
    表示不同用户**对于不同元素的偏好程度**，取值范围[0,1]，1代表很喜欢，0代表不喜欢。
  - 物品矩阵P
    表示**每种物品含有各种元素（特征）的成分**
  - 计算：
    通过将对应向量的元素做内积运算，得到用户对该物品的喜好程度。相应的可以得到用户对每个物品的评分矩阵

+ FunkSVD with Bias 算法
  - 思想：**把求解P、Q的参数问题转换成最优化问题，通过训练集里面的观察值,利用最小化来学习用户矩阵和物品矩阵。**
  - 算法过程
  1. 在有用户矩阵和物品矩阵的前提下，若要计算用户 $u$ 对物品 $i$ 的评分， 可以根据公式：
   $$
   \operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{k=1}^{K} p_{u, k} q_{i,k}
   $$
   其中，向量 $p_u$ 表示用户 $u$ 的隐向量，向量  $q_i$ 表示物品 $i$ 的隐向量。

  2. **随机初始化**一个用户矩阵 $U$ 和一个物品矩阵 $V$，获取每个用户和物品的初始隐语义向量。一般是与`1/sqrt(F)`成正比，F为隐向量维度。

  3. 计算预测得分 with bias
   $$\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}$$.其中，$\mu$反映推荐模型整体的平均评分，一般为样本均值；$b_u$为用户偏差系数。可以使用用户 $u$ 的评分均值，也可作为训练参数；$b_i$为物品偏差系数。可以使用物品 $i$ 的得分均值，也可以当做训练参数。

  4. 对于评分矩阵中的每个元素，计算预测误差 $e_{u i}=r_{u i}-\hat{r}_{u i}$，对所有训练样本的平方误差进行累加：
   $$
   \operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)^{2}
   $$为方便后续求解，给 $SSE$ 增加系数 $1/2$ ：
     $$
     \operatorname{SSE}=\frac{1}{2} \sum_{u, i} e_{u i}^{2}=\frac{1}{2} \sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u k} q_{i k}\right)^{2}
     $$

  5.  前面提到，模型预测越准确等价于预测误差越小，那么优化的目标函数变为：
  $$
  \begin{aligned}
  \min _{q^{*}, p^{*}} \frac{1}{2} \sum_{(u, i) \in K} &\left(r_{u i}-\left(\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}\right)\right)^{2} \\
  &+\lambda\left(\left\|p_{u}\right\|^{2}+\left\|q_{i}\right\|^{2}+b_{u}^{2}+b_{i}^{2}\right)
  \end{aligned}
  $$ 
  $K$ 表示所有用户评分样本的集合，**即评分矩阵中不为空的元素**，其他空缺值在测试时是要预测的。该目标函数需要优化的目标是用户矩阵 $U$ 和一个物品矩阵 $V$。

  1. 对于给定的目标函数，可以通过梯度下降法对参数进行优化。

   + 求解目标函数 $SSE$ 关于用户矩阵中参数 $p_{u,k}$ 的梯度：
     $$
     \frac{\partial}{\partial p_{u,k}} S S E=\frac{\partial}{\partial p_{u,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial p_{u,k}} e_{u i}=e_{u i} \frac{\partial}{\partial p_{u,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} q_{i,k}
     $$

   + 求解目标函数 $SSE$ 关于 $q_{i,k}$ 的梯度：
     $$
     \frac{\partial}{\partial q_{i,k}} S S E=\frac{\partial}{\partial q_{i,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial q_{i,k}} e_{u i}=e_{u i} \frac{\partial}{\partial q_{i,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} p_{u,k}
     $$

  2. 参数梯度更新
   $$
   p_{u, k}=p_{u,k}-\eta (-e_{ui}q_{i, k})=p_{u,k}+\eta e_{ui}q_{i, k} \\ 
   q_{i, k}=q_{i,k}-\eta (-e_{ui}p_{u,k})=q_{i, k}+\eta e_{ui}p_{u, k}\\
   \frac{\partial}{\partial b_{i}} S S E=-e_{u i}+\lambda b_{i}\\
   \frac{\partial}{\partial b_{u}} S S E=-e_{u i} +\lambda b_{u}
   $$ 其中，$\eta$ 表示学习率，用于控制步长。当**参数很多**的时候，就是两个矩阵很大的时候，往往容易陷入**过拟合**的困境，需要在目标函数上面加上正则化的损失。

  - 原理图，==分解出的k维特征是模型待学习的参数==
<div align=center>
<img src="https://img-blog.csdnimg.cn/20200823101513233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:70%;" />
</div>

## Neural Collaborative Filtering (NeuralCF)

### 模型结构
<div align="center">
  <img src="https://static001.geekbang.org/resource/image/5f/2c/5ff301f11e686eedbacd69dee184312c.jpg" alt="NeuralCF Model" style="zoom:33%;">
</div>

### 原理
- **输入特征**：用户ID和项目ID转换为OneHot向量，并映射成指定维度的稠密向量，解决冷启动问题。
- **GMF（广义矩阵分解部分）**：用户与物品特征矩阵逐元素点积，通过线性方法学习特征。
- **MLP**：设置用户和物品的MLP，通过特征组合拼接embedding，经过线性层得到MLP的输出。
- **最终输出**：拼接GMF与MLP特征，通过线性层得到最终输出。

### 优化
$$
L_{sqr}=\sum_{(u,i)\in y\cup y^-}w_{ui}(y_{ui}-\hat{y}_{ui})^2
$$
其中 $w_{ui}$ 为超参数，给每个样本赋权重。

$$
p(y,y^-|P,Q,\Theta_f)=\prod_{(u,i)\in{y}}\hat{y}_{ui}\prod_{(u,j)\in{y^-}}(1-\hat{y}_{uj})
$$

$$
L=-\sum_{(u,i)\in{y}}log\hat{y}_{ui}-\sum_{(u,j)\in{y^-}}log(1-\hat{y}_{uj})=-\sum_{(u,i)\in{y}\cup{y}^-}y_{ui}log \hat{y}_{ui}+(1-y_{ui})log(1-\hat{y}_{ui})
$$
使用随机梯度下降（SGD）进行训练优化。这个函数等价于交叉熵损失函数(binary cross-entropy loss)。通过对NCF进行概率处理，将隐性反馈的推荐问题当做二分类问题来解决。对于负样本 $y^-$，每次迭代均匀地从未观察到交互作用中采样作为负样本，控制采样比例。

**注**：MF是NCF模型的一个特例。

# 基于向量召回
## FM模型（分解机）

### 模型形式

$$
y = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n}\sum_{i+1}^n\lt v_i,v_j\gt x_ix_j
$$

改进思想：**为每个 $x_i$ 计算一个 embedding，然后将两个向量之间的 embedding 做内积得到之前所谓的 $w_{ij}$**。这使得即使两个特征之前从未在训练集中**同时**出现，只需要 $x_i$ 和其他的 $x_k$ 同时出现过就可以计算出 $x_i$ 的 embedding，大大提升了模型的泛化能力。**当交叉项参数 $w_{ij}$ 全为 0 的时候，整个模型就退化为普通的 LR 模型**。

---

公式中各参数的意义：

- $\omega_{0}$：**全局偏置**；
- $\omega_{i}$：模型第 $i$ 个变量的权重；
- $\omega_{ij} = < v_{i}, v_{j}>$：特征 $i$ 和 $j$ 的交叉权重；
- $v_{i}$：第 $i$ 维特征的隐向量；
- $<\cdot, \cdot>$：向量点积；
- $k(k<<n)$：隐向量的长度，包含 $k$ 个描述特征的因子。

---

* 降低时间复杂度的证明

利用 $\sum$ 运算的线性性质，公式可以化简为：

$$
\begin{align} 
\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{<v_i,v_j>x_ix_j}}
&= \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{<v_i,v_j>x_ix_j}} - \frac{1}{2} {\sum_{i=1}^{n}{<v_i,v_i>x_ix_i}} \\
&= \frac{1}{2} \left( \sum_{i=1}^{n}{\sum_{j=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \sum_{i=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \right) \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right) \cdot \left( \sum_{j=1}^{n}{v_{j,f}x_j} \right) - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right)^2 - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} 
\end{align}
$$

---

* 解释

- $v_{i,f}$ 是一个具体的值；
- **第 1 个等号**：对称矩阵 $W$ 的对角线上半部分；
- **第 2 个等号**：将向量内积 $<v_i, v_j>$ 展开为累加和的形式；
- **第 3 个等号**：提出公共部分；
- **第 4 个等号**：$i$ 和 $j$ 相当于表示为相同的平方过程。

### 用于召回的改进

## item2vec召回

### word2vec方法

- **one-hot编码的缺陷**：
  1. 矩阵稀疏，尤其是当特征数量很大的时候
  2. 构成的词向量为正交运算，无法通过数学运算计算词之间的相似性

- **word2Vec算法**：
  1. 使用大量文本预料库
  2. 构建的词汇表中，每一个单词都由宇哥词向量表示
  3. 遍历文本的每一个位置t，都有中心词c与上下文词o(outside)
  4. 再整个语料库上，使用数学方法，最大化o在单词c周围出现的概率，进而得到每一个单词的dense表示
  5. 迭代更新，直到达到最佳效果
   
  - 模型结构
  - 
  输入为1 X V维的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词），单隐藏层（隐藏层的维度为N，这里是一个超参数，也就是词向量的维度），输出为1 X V维的softmax层的模型。$W^{I}$为V X N的参数矩阵，$W^{O}$为N X V的参数矩阵

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片8.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **Skip-gram模型**
  - 目的：最大化单词o在单词c周围出现的概率，也就是\(arg max P(o|c)\).通过设置窗口大小来控制考虑的元素。具体如下如图所示。通过设置窗口为2，然后不断滑动窗口，也从而得到了所有位置元素的概率值。

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片3.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

  - 求解：极大似然法 $ max\prod_{c} \prod_{o}P(o|c) $， 也就是
  \(\prod_{t=1}^{T} \prod_{\substack{j=-m \\ j\neq0}}^{m} P(w_{t+j}|w_t;\theta)\), 
  对整体的函数取log，并加负号。得到最终的损失函数：\(\frac{1}{T} \sum_{t=1}^{T} \sum_{\substack{j=-m \\ j \neq 0}}^{m} \log p(w_{t+j}|w_t+\theta)\)
  
  - \(P(o|c)\)计算：使用中心词c与上下文词o的相似性计算，使用向量的点积表示$u_o \cdot v_c$，然后使用softmax函数映射成一个概率值，如下。每个词都会有两个词向量，一个是自己作为中心词的向量，一个是自己作为上下文词的向量。
  
  $$
  \frac{1}{T} \sum_{t=1}^{T} \sum_{\substack{j=-m \\ j \neq 0}}^{m} \log p(w_{t+j}|w_t+\theta)
  $$

  - 结构：
    ==给定中心词，预测周围的词==

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220424105817437.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **CBOW**
  - 模型结构
  
  == 给定周围词，预测中心词==

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片10.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **负采样**
  - softmax的问题：分母需要在整个单词表上计算乘积与指数运算，计算资源消耗很大。
  - 负采样：
  损失函数如下，其中$\sigma$为sigmoid函数$1/(1+e^{-x})$，$u_{o}$为实际样本中的上下文词的词向量，而$u_{k}$为按一定的规则随机选出的K个单词。由单调性规则，$u_{o}^T \cdot v_c$越大，损失函数越小，而$u_{k}^T \cdot v_c$越小，损失函数越大

  $$
  J_{neg_{sample}}(b_{u_o}, v_c, U) = -\log \sigma({u_o}^Tv_C) - \sum_{k\in K(\text{sampled indices})} \log \sigma(-u_k^Tv_C)
  $$
  - 单词 $w$ 作为负样本时，被采样到的概率：
  
  $$
  \frac{[\operatorname{counter}(w)]^{0.75}}{\sum_{u \in \mathcal{W}}[\operatorname{counter}(u)]^{0.75}}
  $$

  - 单词 $w$ 作为中心词时，被丢弃的概率：
  - 
  $$
  \operatorname{prob}(w)=1-\sqrt{\frac{t}{f(w)}}
  $$

  - 关于$v_c$的导数：

  $$ 
  \begin{aligned}
  \frac{\partial J_{\text{neg-sample}}(\boldsymbol v_c, o, \boldsymbol U)}{\partial \boldsymbol v_c} &= -\frac{\sigma(\boldsymbol u_o^T \boldsymbol v_c)(1 - \sigma(\boldsymbol u_o^T \boldsymbol v_c))}{\sigma(\boldsymbol u_o^T \boldsymbol v_c)} \frac{\partial (\boldsymbol u_o^T \boldsymbol v_c)}{\partial \boldsymbol v_c} - \sum_{k=1}^{K} \frac{\partial \log(\sigma(-\boldsymbol u_k^T \boldsymbol v_c))}{\partial \boldsymbol v_c}\\ &= -(1 - \sigma(\boldsymbol u_o^T \boldsymbol v_c)) \boldsymbol u_o + \sum_{k=1}^{K} (1 - \sigma(-\boldsymbol u_k^T \boldsymbol v_c)) \boldsymbol u_k
  \end{aligned}
  $$

### item2Vec召回

- **原理**：基于物品集合进行训练，丢弃物品的时间与空间信息。同时，假设对于一个集合的物品，它们之间是相似的，与用户购买它们的顺序、时间无关。

- **目标函数**：
$$
\frac{1}{K} \sum_{i=1}^{K} \sum_{j \neq i}^{K} \log p\left(w_{j} \mid w_{i}\right)
$$

- **相似度计算**：使用余弦相似度
- **问题**：计算不同物品之间的相似度时，仍然会依赖不同物品之间的共性，无法解决冷启动问题。一种解决方法是取出与冷启物品类别相同的非冷启物品，将它们向量的均值作为冷启动物品的向量表示。

## Airbnb召回

### Embedding方法
1. 用于描述短期实时性的个性化特征 Embedding：listing Embeddings（listing代表房源）
   - 学习来源：通过用户的点击对话学习特征，表示房源的短期实时特征。给定数据集 $ \mathcal{S} $ ，其中包含了 $ N $ 个用户的 $ S $ 个点击 session（序列）。

     - 每个 session $ s=\left(l_{1}, \ldots, l_{M}\right) \in \mathcal{S} $ ，包含了 $ M $ 个被用户点击过的 listing ids 。
     - 对于用户连续两次点击，若时间间隔超过了30分钟，则启动新的 session。
   - 优化：在得到多个用户点击的session之后，基于word2Vec的SkipGram模型学习不同的listing embedding表示。最大化目标函数：
    $$ 
    \mathcal{L}=\sum_{s \in \mathcal{S}} \sum_{l_{i} \in s}\left(\sum_{-m \geq j \leq m, i \neq 0} \log \mathbb{P}\left(l_{i+j} \mid l_{i}\right)\right) 
    $$
    其中，$\mathbb{P}\left(l_{i+j} \mid l_{i}\right)$ 基于softmax函数，表示一个session中，已知中心listing $l_i$ 来预测上下文 listing $l_{i+j}$ 的概率，也就是：
    $$ 
    \mathbb{P}\left(l_{i+j} \mid l_{i}\right)=\frac{\exp \left(\mathbf{v}{l{i}}^{\top} \mathbf{v}{l{i+j}}^{\prime}\right)}{\sum_{l=1}^{|\mathcal{V}|} \exp \left(\mathbf{v}{l{i}}^{\top} \mathbf{v}_{l}^{\prime}\right)} $$
    其中， $ \mathbf{v}{l{i}} $ 表示 listing $ l_i $ 的 Embedding 向量， $ |\mathcal{V}| $ 表示全部的物料库的数量。由于物料库过大，需要做负采样处理，负采样的目标函数为：
    $$ 
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}{p}} \log \frac{1}{1+e^{-\mathbf{v}{c}^{\prime^{\prime}} \mathbf{v}{l}}}+\sum{(l, c) \in \mathcal{D}{n}} \log \frac{1}{1+e^{\mathbf{v}{c}^{\prime} \mathbf{v}_{l}}} 
    $$ 
    - 正负样本集构建
      - 使用 booked listing 作为全局上下文。booked listing 表示用户在 session 中最终预定的房源，一般只会出现在结束的 session 中。
      - Airbnb 将最终预定的房源，始终作为滑窗的上下文，即**全局上下文**。如下图，对于当前滑动窗口的 central listing，实线箭头表示context listings，虚线（指向booked listing）表示 global context listing。

    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片1653053823336-0564b2da-c993-46aa-9b22-f5cbb784dae2.png" alt="img" style="zoom:50%;" />

    - booked listing 作为全局正样本，故优化的目标函数更新为：

    $$
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}_{p}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime^{\prime}} \mathbf{v}_{l}}}+\sum_{(l, c) \in \mathcal{D}_{n}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{l}}} +
    \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{l_b}}}
    $$

    - 优化负样本的选择
      - 用户通过在线网站预定房间时，通常只会在同一个 market （将要停留区域）内进行搜索。
   
      - 对于用户点击过的样本集 $ \mathcal{D}_{p} $ （正样本集）而言，它们大概率位于**同一片区域**。考虑到负样本集 $ \mathcal{D}_{n} $ 是随机抽取的，大概率来源不同的区域。
   
      - Airbnb 发现这种样本的不平衡，在学习同一片区域房源的 Embedding 时会得到次优解。
   
      - 解决办法也很简单，对于每个滑窗中的中心 lisitng，其负样本的选择新增了**与其位于同一个 market 的 listing**。至此，优化函数更新如下：
     
    $$
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}_{p}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime^{\prime}} \mathbf{v}_{l}}}+\sum_{(l, c) \in \mathcal{D}_{n}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{l}}} +\log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{l_b}}} + 
    \sum_{(l, m_n ) \in \mathcal{D}_{m_n}} \log \frac{1}{1+e^{\mathbf{v}_{m_n}^{\prime} \mathbf{v}_{l}}}
    $$ 

      - $ \mathcal{D}_{m_n} $ 表示与滑窗中的中心 listing 位于同一区域的负样本集。
      - 冷启动：根据房源信息，查找最相似的三个房源，用三个房源的均值作为新的房源的embedding表示。

2. 用于描述长期的个性化特征 Embedding：user-type & listing type Embeddings
   - 潜在问题：
     - 需要基于booking session进行学习，但是数据量很小，因为booking本身就是低频率时间
     - 如果用户只预定过单个数量的房源，则无法从该会话中学习到embedding信息。因为要学习有效的embedding，该实体必须至少出现五次以上。
     - booking的时间跨度会比较大，无法保证用户在这么长的时间跨度里兴趣是否发生变化。
   - 改进：定一个 booking sessions 集合 $\mathcal{S}_{b}$ ，其中包含了$M$个用户的 booking session：每个booking session表示为：$s_{b}=\left(l_{b 1}, \ldots, l_{b M}\right)$，$l_{b1}$ 表示 listing_id，学习到 Embedding 记作 $\mathbf{v}{l{i d}}$。也就是兼顾用户的个人信息与房源信息。
   - 训练过程
     - 图例：
      <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片1653131985447-e033cb39-235b-4f46-9634-3b7faec284be.png" alt="img" style="zoom:50%;" />

    - 联合训练 User-type Embedding 和 Listing-type Embedding
      - 如图（a），在 booking session 中，每个元素代表的是 User-type, Listing-type组合。
      - 为了学习在相同向量空间中的 User-type 和 Listing-type 的 Embeddings，Airbnb 的做法是将 User-type 插入到 booking sessions 中。
      - 形成一个（User-type, Listing-type）组成的元组序列，这样就可以让 User-type 和 Listing-type 的在 session 中的相对位置保持一致了。
      
   - User-type 的目标函数：
      
      $$
      \underset{\theta}{\operatorname{argmax}} \sum_{\left(u_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}+\sum_{\left(u_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}
      $$
   
      +  $ \mathcal{D}_{\text {book }} $ 中的 $ u_t $ （中心词）表示 User-type， $ c $ （上下文）表示用户最近的预定过的 Listing-type。 $ \mathcal{D}_{\text {neg}} $ 中的 $ c $ 表示 negative Listing-type。
      +  $ u_t $ 表示 User-type 的 Embedding， $ \mathbf{v}_{c}^{\prime} $ 表示 Listing-type 的Embedding。

   - Listing-type 的目标函数：
     
     $$
     \begin{aligned}
     \underset{\theta}{\operatorname{argmax}} & \sum_{\left(l_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}}+\sum_{\left(l_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}} \\
     \end{aligned}
     $$

     + 同理，不过窗口中的中心词为 Listing-type， 上下文为 User-type。

- Explicit Negatives for Rejections
   - 用户预定房源以后，还要等待房源主人的确认，主人可能接受或者拒绝客人的预定。拒接的原因可能包括，客人星级评定不佳，资料不完整等。
      
   - 前面学习到的 User-type Embedding 包含了客人的兴趣偏好，Listing-type Embedding 包含了房源的属性特征。但是，用户的 Embedding 未包含更容易被哪类房源主人拒绝的潜语义信息房源的 Embedding 未包含主人对哪类客人的拒绝偏好。
      
   - 为了提高用户预定房源以后，被主人接受的概率。同时，降低房源主人拒绝客人的概率。Airbnb 在训练 User-type 和 Listing-type 的 Embedding时，将用户预定后却被拒绝的样本加入负样本集中（如图b）。
      - 更新后，Listing-type 的目标函数：
        
        $$
        \begin{aligned}
        \underset{\theta}{\operatorname{argmax}} & \sum_{\left(u_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}+\sum_{\left(u_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}} \\
        &+\sum_{\left(u_{t}, l_{t}\right) \in \mathcal{D}_{\text {reject }}} \log \frac{1}{1+\exp ^{\mathrm{v}_{{l_{t}}}^{\prime} \mathrm{v}_{u_{t}}}} 
        \end{aligned}
        $$
      
      - 更新后，User-type 的目标函数：
        
        $$
        \begin{aligned}
        \underset{\theta}{\operatorname{argmax}} & \sum_{\left(l_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}}+\sum_{\left(l_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}} \\
        &+\sum_{\left(l_{t}, u_{t}\right) \in \mathcal{D}_{\text {reject }}} \log \frac{1}{1+\exp ^{\mathrm{v}^{\prime}_{u_{t}} \mathrm{v}_{l_{t}}}}
        \end{aligned}
        $$

## YoutubeDNN推荐系统

### 挑战：
  1. Scale(规模): 视频数量非常庞大，大规模数据下需要分布式学习算法以及高效的线上服务系统，论文体现这一点的是召回模型线下训练的时候，采用了**负采样**的思路，线上服务的时候，采用了**hash映射**，然后近邻检索的方式来满足实时性的需求.
  2. Freshness(新鲜度):用户实时上传，且实时访问，最新的视频往往容易博得用户的眼球。为了让模型学习到用户对新视频有偏好，策略里面加了一个"example age"作为体现。
  3. Noise(噪声): 由于数据的稀疏和不可见的其他原因，数据里面的噪声非常多，需要让这个推荐系统变得鲁棒。这个涉及到召回和排序两块，召回上需要考虑更多实际因素，比如非对称消费特性，高活用户因素，时间因素，序列因素等，并采取了相应的措施， 而排序上做更加细致的特征工程， 尽量的刻画出用户兴趣以及视频的特征、优化训练目标，使用加权的逻辑回归等。召回和排序模型上，都采用了深度神经网络，通过特征的相互交叉，有了更强大的建模能力。

### 模型

- **结构**：
<div align=center>
<img src="https://img-blog.csdnimg.cn/1c5dbd6d6c1646d09998b18d45f869e5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:150%;" /> 
</div>

$$
\downarrow
$$

<div align=center>
<img src="https://img-blog.csdnimg.cn/aeae52971a1345a98b310890ea81be53.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:90%;" /> 
</div>

  - **召回侧**：==快速从海量物品中找到用户潜在感兴趣的物品==
    - 输入与输出：输入一般是用户的点击历史，以及人口统计学特征；输出是与用户相关的候选视频集合。
    - 召回方式：一种基于策略进行召回，也就是根据真实场景进行设定，取决于工作经验；另一种是监督模型 + embedding。

  - **精排侧**：==融入更多负责特征，使用复杂的模型进行精准个性化推荐==
    - 关键点：特征工程、模型设计、训练方法

- **召回侧细节**：
  在时刻$t$下， 用户$U$在背景$C$下对每个视频$i$的观看行为建模如下：
  $$
  P\left(w_{t}=i \mid U, C\right)=\frac{e^{v_{i} u}}{\sum_{j \in V} e^{v_{j} u}}
  $$

  结构如下。将用户观看历史视频的embedding、搜索记录、用户人文特征作为模型的input。经过DNN模型的特征组合与降维，得到用户向量。item向量使用w2v方法训练后得到embedding矩阵。
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/724ff38c1d6448399edb658b1b27e18e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>

- **训练数据选取与生成**：
  - 来源于全部的观看记录，以及从其他渠道观看的视频；
  - 正样本：将训练数据来源于用户的隐式数据（隐式数据指的是用户在平台上的行为数据，而不是直接的反馈（如评分或评论））并且看完的视频；
  - 负样本：从视频库中随机选取，或者将曝光的但是用户没有点击的视频作为负样本。
  - trick：1、训练数据应该对每个用户选取相同的样本数，确保每个用户对模型训练过程中的损失函数和权重的贡献是均衡的，避免**某些特别活跃的用户**在训练过程中对损失函数的影响过大，从而影响模型的训练效果；2、避免模型了解不该了解的信息，也就是消除数据的时序信息。
  - 滑动窗口：用于解决用户以及行为少的问题。通过设置滑动窗口，生成多条训练样本。例如一个用户的历史观看记录是"abcdef"，那么采用滑动窗口，可以是abc预测d, bcd预测e, cde预测f。理论基础是==非对称观看概率：用户开始浏览范围较广，之后浏览范围逐渐变窄==
  - 解决信息泄露：仅仅使用历史信息作为输入，不让模型接触到用户的未来行为。图a是大部分协同过滤的方法，选取全局观看信息作为模型输入，会造成信息穿越；图b为目前主流的数据构建方式。
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/049cbeb814f843fd97638ef02d6c5703.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_2,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>

  - Example Age 特征
    - 原因：视频流行度随着时间的分布是高度非稳态变化的。用户倾向观看最新的视频，而忽略与其的相关性。下图绿色曲线为流行度的经验分布。而在训练时，由于选取的是历史数据，也就是给定时间段内播放量的均值，这会导致模型对视频播放量预测值的期望趋于平均热度（蓝色线）
    <div align=center>
    <img src="https://img-blog.csdnimg.cn/15dfce743bd2490a8adb21fd3b2b294e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
    </div>

    - 定义：\(t_{max} - t\),其中\(t_{max}\)为训练数据中所有样本的时间最大值，$t$为当前样本时间
    - 时间bias：一个视频上传到样本生成的时间跨度。对某个视频的不同样本，图中的定义是等价的。因为和是常数。$ t_{\text {video age }}+t_{\text {example age }}=\text { Const } $。也就是视频上传时间到采样时间右端点这一跨度。
    但是example age可以在线上预测时设置为常数，也就是**所有的item是统一的**，只需要计算一次；而vedio age 与每个视频的上传时间有关，每个item都需要计算一次。并且，**不同的视频，对应的example age的范围是一致的**，仅仅依赖**训练数据的采样时间**，方便归一化操作。
    <div align=center>
    <img src="https://img-blog.csdnimg.cn/10475c194c0044a3a93b01a3193e294f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
    </div>

- **线上服务**
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/86751a834d224ad69220b5040e0e03c9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>
  
  - k近邻搜索：提前将用户与视频的embedding存储，在用户上线后进行匹配。常用的检索工具有annoy、faiss

## 双塔召回

### 经典双塔
- **模型结构**
分为用户塔与物品塔，分别根据两侧的特征输入，利用DNN得到各自的embedding表示。再计算两者的相似度。
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522103456450.png" style="zoom:60%;"/>
</div>

相应被抽取的概率值计算如下，$s(x,y)$表示两个向量的相似度，$P(y|x;\theta)$表示预测类别的概率，$M$表示物料库所有的item。

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522110742879.png" style="zoom:60%;"/>
</div>

- **效果与缺陷**：整体召回的速度非常快，能够满足实际的需求，相应的代价是牺牲模型的部分精准性，因为两侧没有特征交叉。

### SENet双塔

- **模型结构**

$$SENet$$

<div align=center>
<img src="https://img-blog.csdn.net/20170916211038886?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" style="zoom:80%;"/>
</div>

$$
\downarrow
$$

$$ SENet双塔 $$

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522152508824.png" style="zoom:70%;"/>
</div>

- SENet
  - Squeeze阶段：对embedding信息做汇总与压缩，也就是求均值
  $$
  z_i = F_{sq}(e_i) = \frac{1}{k} \sum_{t=1}^k e_i^{(t)}$$

  其中k表示Embedding的维度，Squeeze阶段是将每个特征的Squeeze转换成单一的数值。

  - Excitation阶段：这阶段是根据上一阶段得到的向量进行缩放，即将上阶段的得到的 $1 \times f$ 的向量$Z$先压缩成 $1 \times \frac{f}{r}$ 长度，然后在放回到  $1 \times f$ 的维度，其中$r$表示压缩的程度。这个过程的具体操作就是经过两层DNN。
    ​                                                                  $$A = F_{ex}(Z) = \sigma_2(W_2\sigma_1(W_1Z)) $$
    该过程可以理解为：对于当前所有输入的特征，通过相互发生关联，来**动态地判断哪些特征重要，哪些特征不重要**，而这体现在Excitation阶段的输出结果 $A$，其反应每个特征对应的**重要性权重**。

  - Re-weight阶段：是将Excitation阶段得到的每个特征对应的权重 $A$ 再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。

  ​																		$$V=F_{ReWeight }(A,E)=[a_1 \cdot e_1,⋯,a_f \cdot e_f]=[v_1,⋯,v_f]$$

- SENet双塔的有效性：在底层过滤了特征中的无效低频特征，使得双塔在高层交互时仍然有较多的有用信息。当然，也可以在各自的塔中增加多通道，也就是多个SENet+DNN的组合，对各自的特征从不同的兴趣方面进行提取。

### 多目标双塔

根据业务中不同的评价指标，比如关注、点赞等行为，需要建立不同的塔得到相应的结果，再对所有塔的损失进行优化。具体如下图。在两侧分别通过多个通道为**每一个任务**得到一个对应的user embedding 与item embedding，再针对不同的优化目标计算相应的相似度以及损失。最终的目的是优化多任务的损失。
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220523113206177.png" style="zoom:60%;"/>
</div>

### 细节问题

- **归一化与温度系数**：对user与item端输出的embedding做归一化，并对最后的内积结果除温度系数
  - 归一化：对两侧的输出做l2归一化.因为向量点积距离为非度量空间，不满足三角不等式，且向量**内积不保序**；通过归一化将点击行为转换为欧式距离。
  $$
  \begin{aligned}
  u(x,\theta) \leftarrow &= \frac{u(x,\theta)}{||u(x,\theta)||_2}\\
  v(x,\theta) \leftarrow &= \frac{v(x,\theta)}{||v(x,\theta)||_2}
  \end{aligned}
  $$

  - 温度系数：对归一化的向量计算内积后，除固定的超参数\(r\)。
  $$
  s(u,v) = \frac{<u(x,\theta), v(x,\theta)>}{r}
  $$

#### 负样本采样

与排序模型不同，召回面对的是全部item，因此不能像排序一样只考虑没有被点击的item，需要保证负样本在线下线上的分布尽量一致。也就是尽可能增加没有被曝光的item
- **全局随机采样**:从全局候选的item中选取一定数量的item作为负样本。但由于item存在八二定律，也就是少数热门物料占据大部分曝光与点击。因此纯随机方法只能让模型学习一些粗粒度的差异。
- **全局随机采样 + 热门打压**：对有着高曝光与点击的item进行打压，也就是欠采样。让模型更关注非热门item。同时还应当在热门item做负样本时进行适当的过采样，因为热门的item与用户的兴趣相似度较高，模型需要更注重在item与用户兴趣相似时，怎么区分。
- **Hard Negative增强样本**：选取一部分匹配度适中的item，用以加强模型在训练时的难度，从而让模型学习到更多的细粒度的信息。也就是正负样本在某些方面是具有一定的相似性的。
- **Batch内随机选择负采样**：将batch内除正样本之外的其他item作为负样本。也就是将其他样本的正样本随机采样为自己的负样本。潜在的问题是：如果batch的分布与实际差异较大会出现问题；并且batch内仍然存在热门效应，需要对热门物品进行打压。

### Youtube双塔

- **原理**：给定一个查询集 $Query: \left\{x_{i}\right\}_{i=1}^{N}$ 和一个物品集 $Item:\left\{y_{j}\right\}_{j=1}^{M}$。
  + $x_{i} \in X,\quad y_{j} \in \mathcal{Y}$ 是由多种特征组成的高维混合体。
  + 推荐的目标是对于给定一个 $query$，检索到一系列 $item$ 子集用于后续排序任务。

- **结构**：
<div align=center>
<img src="https://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220506202824884.png" alt="image-20220506202824884" style="zoom:40%;" />
</div>
通过对用户与物品分别建立不同的模型，投影到相同维度的区间

$$
u: X \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{k}\\
v: y \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{k}
$$

模型的输出是用户与物品向量之间的内积，其中$\theta$是待学习参数。
$$
s(x, y)=\langle u(x, \theta), v(y, \theta)\rangle
$$
样本集表示成$\{query, item, reward \}$的形式，如下所示。 $r_i$ 可以扩展来捕获用户对不同候选物品的参与度。
$$
\mathcal{T}:=\left\{\left(x_{i}, y_{i}, r_{i}\right)\right\}_{i=1}^{T}
$$

- **流程**：
1.  给定用户 $x$，基于 softmax 函数从物料库 $M$ 中选中候选物品 $y$ 的概率为：
    $$
    \mathcal{P}(y \mid x ; \theta)=\frac{e^{s(x, y)}}{\sum_{j \in[M]} e^{s\left(x, y_{j}\right)}}
    $$

    * 考虑到相关奖励 $r_i$ ，加权对数似然函数的定义如下：  

      $$
      L_{T}(\theta):=-\frac{1}{T} \sum_{i \in[T]} r_{i} \cdot \log \left(\mathcal{P}\left(y_{i} \mid x_{i} ; \theta\right)\right)
      $$
2.  原表达式 $\mathcal{P}(y \mid x ; \theta)$ 中分母需要遍历所有的物品，计算成本太高，故对分母中的物品要进行负采样。为了提高负采样的速度，一般是直接从训练样本所在 Batch 中进行负样本选择。于是有：
    $$
    \mathcal{P}_{B}\left(y_{i} \mid x_{i} ; \theta\right)=\frac{e^{s\left(x_{i}, y_{i}\right)}}{\sum_{j \in[B]} e^{s\left(x_{i}, y_{j}\right)}}
    $$
    * 其中，$B$ 表示与样本 $\{x_i,y_j\}$ 同在一个 Batch 的物品集合。
    * 举例来说，对于用户1，Batch 内其他用户的正样本是用户1的负样本。
3.  一般而言，负采样分为 Easy Negative Sample 和 Hard Negative Sample。Easy Negative Sample 是直接从全局物料库中随机选取负样本。
   由于每个用户感兴趣的物品有限，而物料库又往往很大，故即便从物料库中随机选取负样本，也大概率是用户不感兴趣的。在真实场景中，存在八二定律，随机选择负样本往往选中的是冷门物品。这就会造成马太效应，热门物品更热，冷门物品更冷。一种解决方式是，在对训练样本进行负采样时，提高热门物品被选为负样本的概率，工业界的经验做法是**物品被选为负样本的概率正比于物品点击次数的 0.75 次幂**。
   在 Batch 内进行负采样，存在热门物品被选为负样本的概率过高，导致热门物品被过度打压的问题。
   本文为了避免对热门物品进行过度惩罚，进行了纠偏。公式如下。在内积 $s(x_i,y_j)$ 的基础上，减去了物品 $j$ 的采样概率的对数。
      $$
      s^{c}\left(x_{i}, y_{j}\right)=s\left(x_{i}, y_{j}\right)-\log \left(p_{j}\right)
      $$

4. 纠偏后，物品 $y$ 被选中的概率为：
    $$
    \mathcal{P}_{B}^{c}\left(y_{i} \mid x_{i} ; \theta\right)=\frac{e^{s^{c}\left(x_{i}, y_{i}\right)}}{e^{s^{c}\left(x_{i}, y_{i}\right)}+\sum_{j \in[B], j \neq i} e^{s^{c}\left(x_{i}, y_{j}\right)}}
    $$

    + 此时，batch loss function 的表示式如下：

    $$
    L_{B}(\theta):=-\frac{1}{B} \sum_{i \in[B]} r_{i} \cdot \log \left(\mathcal{P}_{B}^{c}\left(y_{i} \mid x_{i} ; \theta\right)\right)
    $$
    + 通过 SGD 和学习率，来优化模型参数 $\theta$ ：

    $$
    \theta \leftarrow \theta-\gamma \cdot \nabla L_{B}(\theta)
    $$

5. Normalization and Temperature

    * 最后一层，得到用户和物品的特征 Embedding 表示后，再进行进行 $l2$ 归一化。本质上，其实是将用户和物品的向量内积转换为了余弦相似度
      $$
      \begin{aligned}
      u(x, \theta) \leftarrow u(x, \theta) /\|u(x, \theta)\|_{2}\\
      v(y, \theta) \leftarrow v(y, \theta) /\|v(y, \theta)\|_{2}
      \end{aligned}
      $$

    * 对于内积的结果，再除以温度参数 $\tau$：
      $$
      s(x, y)=\langle u(x, \theta), v(y, \theta)\rangle / \tau
      $$

      + 论文提到，这样有利于提高预测准确度。
      + 从实验结果来看，温度参数 $\tau$ 一般小于 $1$，所以感觉就是**放大了内积结果**。

- **流频估计算法**
考虑一个随机的数据batch，每个 batch 中包含一组物品。现在的问题是如何估计一个 batch 中物品 $y$ 的选取概率。具体方法如下：

  + 利用全局步长，将对物品采样频率 $p$ 转换为 对 $\delta$ 的估计，其中 $\delta$ 表示连续两次采样物品之间的平均步数。
  + 例如，某物品平均 50 个步后会被采样到，那么采样频率 $p=1/\delta=0.02$ 。

**具体的实现方法为：**

1. 建立两个大小为 $H$ 的数组 $A,B$ 。

2. 通过哈希函数 $h(\cdot)$ 把每个物品映射为 $[H]$ 范围内的整数。

3. 数组 $A$ 中存放的 $A[h(y)]$ 表示物品 $y$ **上次被采样**的时间， 数组 $B$ 中存放的 $B[h(y)]$ 表示物品 $y$ 的**全局步长**。

   + 假设在第 $t$ 步时采样到物品 $y$，则 $A[h(y)]$ 和 $B[h(y)]$ 的更新公式为：
     $$
     B[h(y)] \leftarrow(1-\alpha) \cdot B[h(y)]+\alpha \cdot(t-A[h(y)])
     $$

   + 在$B$ 被更新后，将 $t$ 赋值给 $A[h(y)]$ 。

4. 对整个batch数据采样后，取数组 $B$ 中 $B[h(y)]$ 的倒数，作为物品 $y$ 的采样频率，即：
   $$
   \hat{p}=1 / B[h(y)]
   $$

- **多重哈希**：为了解决物品较多时，映射的整数相同导致哈希碰撞的问题，使用多个哈希函数，选取所有估计值的最大值表示连续两次被采样的步长。
  - **具体的算法流程：**

  1. 分别建立 $m$ 个大小为 $H$ 的数组 $\{A\}_{i=1}^{m}$，$\{B\}_{i=1}^{m}$，一组对应的独立哈希函数集合 $\{h\}_{i=1}^{m}$ 。

  2. 通过哈希函数 $h(\cdot)$ 可以把每个物品映射为 $[H]$ 范围内的整数。对于给定的物品 $y$，哈希后的整数记为$h(y)$

  3. 数组 $A_i$ 中存放的 $A_i[h(y)]$ 表示在第 $i$ 个哈希函数中物品 $y$ 上次被采样的时间。数组 $B_i$ 中存放的 $B_i[h(y)]$ 表示在第 $i$ 个哈希函数中物品 $y$ 的全局步长。

  4. 假设在第 $t$ 步采样到物品 $y$，分别对 $m$ 个哈希函数对应的 $A[h(y)]$ 和 $B[h(y)]$ 进行更新：
     $$
     \begin{aligned}
     & B_i[h(y)] \leftarrow(1-\alpha) \cdot B_i[h(y)]+\alpha \cdot(t-A_i[h(y)])\\ \\
     & A_i[h(y)]\leftarrow t
     \end{aligned}
     $$

  5. 对整个 batch 数据采样后，取 $\{B\}_{i=1}^{m}$ 中最大的 $B[h(y)]$ 的倒数，作为物品 $y$ 的采样频率，即：

  $$
  \hat{p}=1 / \max _{i}\left\{B_{i}[h(y)]\right\}
  $$

- **YouTube**召回模型：
  ![image-20220506224501697](https://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220506224501697.png)
在任何时间点，用户正在观看的视频，即**种子视频**，都会提供有关用户当前兴趣的强烈信号。因此，该模型利用了大量种子视频特征以及用户的观看历史记录。候选塔是为了从候选视频特征中学习而构建的。

* Training Label

  * 视频点击被用作**正面标签**。对于每次点击，都构建一个 rewards 来反映用户对视频的不同程度的参与。
  * $r_i$ = 0：观看时间短的点击视频；$r_i$ = 1：表示观看了整个视频。
  
* Video Features

  * YouTube 使用的视频特征包括 categorical 特征和 dense 特征。

    * 例如 categorical 特征有 video id 和 channel id 。
    * 对于 categorical 特征，都会创建一个嵌入层以将每个分类特征映射到一个 Embedding 向量。
    * 通常 YouTube 要处理两种类别特征，分别是 one-hot 和 multi-hot。

* User Features

  * 使用**用户观看历史记录**来捕捉 seed video 之外的兴趣。将用户**最近观看的 k个视频**视为一个词袋（BOW)，然后将它们的 Embedding 平均。
  * 在查询塔中，最后将用户和历史 seed video 的特征进行融合，并送入输入前馈神经网络。

## 图召回
### EGES
==主要贡献:引入side information解决实际中数据稀疏与冷启动的问题==
- **传统方法存在的问题**:
  - 可扩展性：现有的推荐方法无法扩展到拥有众多用户与商品的情况。
  - 稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于部分商品，存在大量商品很少被用户交互。
  - 冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。 

#### 模型结构与原理
方法是基于DeepWalk模型进行改造.目的是通过物品图G学习映射函数$f:V -> R^d$,将节点映射成Embedding.首先基于随机游走为图中的每个节点生成序列,再通过skipGram方法学习每个物品的embedding.
- **构建item-item图**
  先根据用户的session行为(指定时间跨度)序列构建网络结构,序列中相邻的item之间存在带有权重的边,权重是所有的用户序列中,该item对共同出现的次数.同时需要对item与user去噪:item点击停留时间过短|过于活跃的用户|频繁修改的物品.
<div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328133138263.png" style="zoom:80%;"/>
</div>

- **图嵌入(BGE)**
  首先随机游走得到物品序列.随机游走的概率计算方式如下.其中$M_{ij}$为边$e_{ij}$上的权重(也就是item对(i,j)出现的次数)，$N_{+}(v_i)$表示节点$v_i$所有邻居节点集合，随机游走的转移概率是对每个节点所有邻接边权重的归一化结果。
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328144516898.png" style="zoom:80%;"/>
  </div>
  通过随机游走,得到序列.然后为每一个item生成对应的embedding.假设物品之间是独立的,并进行负采样.优化目标就变为下图.
  <div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220418142135912.png" style="zoom:47%;"/>
  </div>
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328145318718.png" style="zoom:80%;"/>
  </div>

- **基于side information的图嵌入(GES)**
  上面的模型无法很好的解决冷启动问题,因为新的物品加入后并没有与用户进行交互,并不会在item图中出现,也就是没法学习相应的embedding.因此模型加入Side Information(类别|店铺|价格等额外信息)辅助训练,通过side information 学习到的embedding代表具体的商品,这样相似的side information能在空间上有相似的表示.
  具体来说,在随机游走之后,每个商品由对应的id以及属性组成,也就是对于序列中的每一个物品可以得到$W^0_V,...W_V^n$,（n+1）个向量表示，$W^0_V$表示物品v，剩下是side information的embedding.将side information整合成一个整体来表示物品,也就是$H_v = \frac{1}{n+1}\sum_{s=0}^n W^s_v$

- **Enhanced GES**
  实际中不同的side information对embedding的贡献不是相等的,因此更应该使用带有权重的池化操作,也就是:
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328154950289.png" style="zoom:80%;"/>
  </div>

  具体的计算公式是,其中$a_i$为用于计算权重的参数向量
  $$
  H_v = \frac{\sum_{j=0}^n e^{a_v^j} W_v^j}{\sum_{j=0}^n e^{a_v^j}}
  $$
  先对$a_v^j$做指数变换,以确保每个边界信息的贡献度都可以大于0,然后做归一化,使得每个特征的权重在[0,1]内.在获取对应的权重之后对各特征做加权聚合,进而得到损失函数为:
  $$
  L(v,u,y)=-[ylog( \sigma (H_v^TZ_u)) + (1-y)log(1 - \sigma(H_v^TZ_u))]
  $$

### PinSAGE
#### GraphSAGE
用于解决图中的节点以及图的结构不断发生变化的情况,GraphSAGE可以通过聚合邻居信息的方式为给定的节点学习相应的embedding表示.具体操作如下:
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220423094435223.png" style="zoom:90%;"/>
</div>

- $h_v^0$表示图节点的初始化表示，等同于节点自身的特征。
- $h_v^k$表示第k层卷积后的节点表示，其来源于两个部分：
  - 第一部分来源于节点v的邻居节点集合$N(v)$，利用邻居节点的第k-1层卷积后的特征$h_u^{k-1}$进行 （ $\sum_{u \in N(v)} \frac{h_u^{k-1}}{|N(v)|}$ ）后，在进行线性变换。这里**借助图上的边将邻居节点的信息通过边关系聚合到节点表示中(简称卷积操作)**。
  - 第二部分来源于节点v的第k-1层卷积后的特征$h_v^{k-1}$，进行线性变换。总的来说图卷积的思想是**在对自身做多次非线性变换时，同时利用边关系聚合邻居节点信息。**
- 最后一次卷积结果作为节点的最终表示$Z_v$。
  
**采样和聚合**
分为两步:首先从所有邻居节点中找出用于聚合的邻居节点集合;然后对采样后的结果进行聚合操作
- **邻居采样**
  根据中心节点集合$B^k$,对集合中每个中心节点使用随机采样,采取固定数目的邻居节点S个,如果该中心点的邻居节点数大于S,则无放回抽样,反之有放回.

  进行邻居采样并固定采样数量S主要是因为：1. 采样邻居节点避免了在全图的搜索以及使用全部邻居节点所导致计算复杂度高的问题；2. 可以通过采样使得部分节点更同质化，即两个相似的节点具有相同表达形式。3. 采样固定数量是保持每个batch的计算占用空间是固定的，方便进行批量训练。

- **聚合函数**(要求构建的函数具有对称性,也就是输入的顺序不影响输出的结果,同时表达能力要求较强)
  - Mean 聚合：首先会对邻居节点按照**element-wise**进行均值聚合，然后将当前节点k-1层得到特征$h_v^{k-1}$与邻居节点均值聚合后的特征 $MEAN(h_u^k | u\in N(v))$**分别**送入全连接网络后**相加**得到结果。
  - Convolutional 聚合：这是一种基于GCN聚合方式的变种，首先对邻居节点特征和自身节点特征求均值，得到的聚合特征送入到全连接网络中。与Mean不同的是，这里**只经过一个全连接层**。
  - LSTM聚合：由于LSTM可以捕捉到序列信息，因此相比于Mean聚合，这种聚合方式的**表达能力更强**；但由于LSTM对于输入是有序的，因此该方法不具备**对称性**。作者对于无序的节点进行**随机排列**以调整LSTM所需的有序性。
  - Pooling聚合：对于邻居节点和中心节点进行一次非线性转化，将结果进行一次基于**element-wise**的**最大池化**操作。该种方式具有**较强的表达能力**的同时还具有**对称性**。

#### PinSAGE
==基于GraphSAGE的原理学习到聚合方法，并为每个图片(pin)学习一个向量表示，然后基于pin的向量表示做item2item的召回==
- **重要性采样**
  在采样时关注更加重要的邻居节点,也就是为每个邻居节点计算一个重要性权重,选TopK的邻居节点作为邻居集合.计算重要性的过程是，以目标节点为起点，进行random-walk，采样结束之后计算**所有节点访问数的L1-normalized作为重要性权重**，同时这个权重也会在聚合过程中加以使用(**加权聚合**).
- **聚合函数
  PinSAGE中的Convolve算法（单层图卷积操作）相当于GraphSAGE算法的聚合过程，在实际执行过程中通过对**每一层**执行一次图卷积操作以得到不同阶邻居的信息，具体过程如下图所示：
  <div align=center>
      <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406202027832.png" style="zoom:110%;"/>
  </div>

  上述的单层图卷积过程如下三步：

  1. 聚合邻居： 先将所有的邻居节点经过一次非线性转化(一层DNN)，再由聚合函数(Pooling聚合) $\gamma$（如元素平均，**加权和**等）将所有邻居信息聚合成目标节点的embedding。这里的加权聚合采用的是通过random-walk得到的重要性权重。
  2. 更新当前节点的embedding：将目标节点当前的向量 $z_u$ 与步骤1中聚合得到的邻居向量 $n_u$ 进行拼接，在通过一次非线性转化。
  3. **归一化操作**：对目标节点向量 $z_u$ 归一化,使得训练时更加稳定。
  
- **基于mini-batch堆叠多层图卷积**
因为实际场景中,用户交互图非常庞大,不可能在一张图上学习所有节点的信息,所以,对mini-batch的所有结点,通过采样的方式逐层寻找相关的邻居结点,再对每一层的结点做图卷积,从而从k阶邻居结点聚合信息
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406204431024.png" style="zoom:60%;"/>
</div>
如上图所示：对于batch内的所有节点(图上最顶层的6个节点)，依次**根据权重采样**，得到batch内所有节点的一阶邻居(图上第二层的所有节点)；然后对于所有一阶邻居再次进行采样，得到所有二阶邻居(图上的最后一层)。节点采样阶段完成之后，与采样的顺序相反进行聚合操作。首先对二阶邻居进行单次图卷积，将二阶节点信息聚合已更新一阶节点的向量表示(其中小方块表示的是一层非线性转化)；其次对一阶节点再次进行图卷积操作，将一阶节点的信息聚合已更新batch内所有节点的向量表示。仅此对于一个batch内的所有的样本通过卷积操作学习到一个embedding，而每一个batch的学习过程中仅**利用与mini-batch内相关节点的子图结构。**

- **训练过程**
PinSage在训练时采用的是 Margin Hinge Loss 损失函数，主要的思想是**最大化正例embedding之间的相关性，同时还要保证负例之间相关性相比正例之间的相关性小于某个阈值(Margin)**。具体的公式如下：

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406210833675.png" style="zoom:100%;"/>
</div>

其中$Z_p$是学习得到的目标节点embedding，$Z_i$是与目标节点相关item的embedding，$Z_{n_k}$是与目标节点不相关item的embedding，$\Delta$为margin值，具体大小需要调参。

对于正样本而言，文中的定义是如果用户在点击的 item q之后**立即点击**了 item i，即认为 < q, i >构成正样本对。具体地，代码中将所有的训练样本构造成用户-项目二部图，然后对batch内的每个 item q，根据item-user-item的元路径进行随机游走，得到被**同一个用户交互过的 item i**，因此组成<q,i>正样本对。

由于模型是用于 item to item的召回，因此优化目标是与正样本之间的表示尽可能的相近，与负样本之间的表示尽可能的远。而图卷积操作会使得具有邻接关系的节点表示具有**同质性**，因此结合这两点，就需要在构建图结构的时，要将**训练样本之间可能存在的边在二部图上删除**，避免因为边的存在使得因卷积操作而导致的信息泄露。

- **负采样**

召回模型最主要的任务是从候选集合中选出用户可能感兴趣的item，直观的理解就是让模型将用户喜欢的和不喜欢的进行区分。然而由于候选集合的庞大数量，许多item之间十分相似，导致模型划分出来用户喜欢的item中会存在一些难以区分的item(即与用户非常喜欢item比较相似的那一部分)。有两种方法:

  - easy 负样本：这里对于mini-batch内的所有pair(训练样本对)会**共享500负样本**，这500个样本从batch之外的所有节点中随机采样得到。这么做可以减少在每个mini-batch中因计算所有节点的embedding所需的时间，文中指出这和为每个item采样一定数量负样本无差异。==用于加速模型收敛到一定范围,也就是模型具有初步的学习能力==
  - hard 负样本：这里使用hard 负样本的原因是根据实际场景的问题出发，模型需要从2百万 item 中识别出最相似的那一个 item。也就是说模型的区分能力不够细致，为了解决这个问题，加入了一些hard样本。hard 负样本是与 q 相似 以及和 i 不相似的物品，具体地的生成方式是将图上的节点计算相对节点 q 的个性化PageRank分值，根据分值的排序随机从2000~5000的位置选取节点作为负样本。==这用来帮助模型提升细粒度方面的能力==

## 序列召回
### MIND
==用单一向量表示用户兴趣不够全面,需要用多个向量表示用户的多种兴趣==

#### 胶囊网络与动态路由
- **胶囊网络**:如下图,胶囊可以看成一组聚合起来输出整个向量的小神经元的组合,向量的每个维度代表实体的某个特征.
![在这里插入图片描述](https://img-blog.csdnimg.cn/1f698efd1f7e4b76babb061e52133e45.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_2,color_FFFFFF,t_70,g_se,x_16#pic_center)
在对胶囊输出的向量做加权汇总后,进行squash操作,计算公式如下:
$$
\begin{aligned}
&u^{1}=W^{1} v^{1} \quad u^{2}=W^{2} v^{2} \\
&s=c_{1} u^{1}+c_{2} u^{2} \\
&v=\operatorname{Squash}(s) =\frac{\|s\|^{2}}{1+\|s\|^{2}} \frac{s}{\|s\|}
\end{aligned}
$$
其中$W^i$参数是可学习的,$c_i$参数是采用动态路由机制现场算出来的
- **动态路由**:对于一个胶囊结构网络,通过迭代的方式计算,算法如下:
 ![在这里插入图片描述](https://img-blog.csdnimg.cn/12fca14263d943318bf3d83180b55e01.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center)
 ![在这里插入图片描述](https://img-blog.csdnimg.cn/82746b6ff8ac47fab6a89788d8d50f9e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center)

 初始化$b_i$，与每一个输入胶囊$u_i$进行对应，也就是"routing logit"， 表示的是输出的这个胶囊与输入胶囊的相关性，和注意力机制里面的score值非常像。由于一开始不知道这个哪个胶囊与输出的胶囊有关系，所以默认相关性分数都一样，然后进入迭代。

在每一次迭代中，首先把分数转成权重，然后加权求和得到$s$，这个很类似于注意力机制的步骤，得到$s$之后，通过归一化操作，得到$a$，接下来要通过$a$和输入胶囊的相关性以及上一轮的$b_i$来更新$b_i$。最后那个公式的作用是：
>如果当前的$a$与某一个输入胶囊$u_i$**非常相关**，即内积结果很大的话，那么相应的下一轮的该输入胶囊对应的$b_i$就会变大， 那么， 在计算下一轮的$a$的时候，与上一轮$a$相关的$u_i$就会占主导，相当于下一轮的$a$与上一轮中和他相关的那些$u_i$之间的路径权重会大一些，这样从空间点的角度观察，就相当于$a$点朝与它相关的那些$u$点更近了一点。

通过若干次迭代之后，得到最后的输出胶囊向量$a$会慢慢的走到与它更相关的那些$u$附近，而远离那些与它不相干的$u$。所以上面的这个迭代过程有点像**排除异常输入胶囊的感觉**。 
![在这里插入图片描述](https://img-blog.csdnimg.cn/2bc074c460fa403f8a98fa24aa4a31a3.png#pic_center)

而从另一个角度来考虑，这个过程其实像是聚类的过程，因为胶囊的输出向量$v$经过若干次迭代之后，会最终停留到与其非常相关的那些输入胶囊里面，而这些输入胶囊，其实就可以看成是某个类别了，因为既然都共同的和输出胶囊$v$比较相关，那么彼此之间的相关性也比较大，于是乎，经过这样一个动态路由机制之后，就不自觉的，把输入胶囊实现了聚类。把和与其他输入胶囊不同的那些胶囊给排除了出去。

下面是上述过程的展开计算过程，这个和RNN的计算有点类似：
![在这里插入图片描述](https://img-blog.csdnimg.cn/c189e1258de64e42b576884844e718a4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center)

#### 整体结构
![在这里插入图片描述](https://img-blog.csdnimg.cn/33b251f8dcb242ad82b2ed0313f6df73.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_2,color_FFFFFF,t_70,g_se,x_16#pic_center)

输入特征为用户base|历史行为|商品属性,用户的历史行为通过胶囊网络得到多个兴趣胶囊,再与DNN进行拼接得到交互后的用户兴趣,在训练阶段,用户兴趣与当前商品经过label-aware attention，然后求softmax损失。在服务阶段,得到相应的用户向量就直接进行搜索.

#### 目标

- **模型输入**:对于模型，每个样本的输入可以表示为一个三元组：$\left(\mathcal{I}_{u}, \mathcal{P}_{u}, \mathcal{F}_{i}\right)$，其中 $\mathcal{I}_{u}$ 代表与用户 $u$ 交互过的物品集，即**用户的历史行为**；$\mathcal{P}_{u}$表示**用户的属性**，例如性别、年龄等；$\mathcal{F}_{i}$ 定义为目标物品 $i$ 的一些特征，例如物品id和种类id等。
- **模型任务**:学习一个从原生特征映射到**用户表示**的函数，用户表示定义为：
$$
\mathrm{V}_{u}=f_{u s e r}\left(\mathcal{I}_{u}, \mathcal{P}_{u}\right)
$$
其中，$\mathbf{V}_{u}=\left(\overrightarrow{\boldsymbol{v}}_{u}^{1}, \ldots, \overrightarrow{\boldsymbol{v}}_{u}^{K}\right) \in \mathbb{R}^{d \times k}$是用户$u$的表示向量，$d$是embedding的维度，$K$表示向量的个数，即**兴趣的数量**。如果$K=1$，那么MIND模型就退化成YouTubeDNN的向量表示方式了。

  目标物品$i$的embedding函数为：
$$
\overrightarrow{\mathbf{e}}_{i}=f_{\text {item }}\left(\mathcal{F}_{i}\right)
$$
其中，$\overrightarrow{\mathbf{e}}_{i} \in \mathbb{R}^{d \times 1}, \quad f_{i t e m}(\cdot)$表示一个embedding&pooling层。

- **最终结果**:根据**目标物品与用户表示向量的内积的最大值作为相似度依据**作为Top N候选物品.
$$
f_{\text {score }}\left(\mathbf{V}_{u}, \overrightarrow{\mathbf{e}}_{i}\right)=\max _{1 \leq k \leq K} \overrightarrow{\mathbf{e}}_{i}^{\mathrm{T}} \overrightarrow{\mathbf{V}}_{u}^{\mathrm{k}}
$$

#### Multi-Interest Extractor Layer(核心)
- **B2I动态路由**
1. **共享双向映射矩阵**。在初始动态路由中，使用固定的或者说共享的双线性映射矩阵$S$而不是单独的双线性映射矩阵， 在原始的动态路由中，对于每个输出胶囊$\vec{c}_{j}^h$，都会有对应的$S_{ij}$，而这里是每个输出胶囊，都共用一个$S$矩阵。 原因有两个：
	1. 一方面，用户行为是可变长度的，从几十个到几百个不等，因此使用共享的双线性映射矩阵是有利于泛化。
	2. 另一方面，希望兴趣胶囊在同一个向量空间中，但不同的双线性映射矩阵将兴趣胶囊映射到不同的向量空间中。因为映射矩阵的作用就是对用户的行为胶囊进行线性映射，由于用户的行为序列都是商品，所以希望经过映射之后，到统一的商品向量空间中去。路由对数计算如下：
$$
b_{i j}=\overrightarrow{\boldsymbol{u}}_{j}^{T} \mathrm{S\overrightarrow{e}}_{i}, \quad i \in \mathcal{I}_{u}, j \in\{1, \ldots, K\}
$$
​		其中，$\overrightarrow{\boldsymbol{e}}_{i} \in \mathbb{R}^{d}$是历史物品$i$的embedding，$\vec{u}_{j} \in \mathbb{R}^{d}$表示兴趣胶囊$j$的向量。$S \in \mathbb{R}^{d \times d}$是每一对行为胶囊(低价)到兴趣胶囊(高阶)之间		的共享映射矩阵。


2. **随机初始化路由对数**。由于利用共享双向映射矩阵$S$，如果再初始化路由对数为0将导致相同的初始的兴趣胶囊。随后的迭代将陷入到一个不同兴趣胶囊在所有的时间保持相同的情景。因为每个输出胶囊的运算都一样了嘛(除非迭代的次数不同，但这样也会导致兴趣胶囊都很类似)，为了减轻这种现象，作者通过高斯分布进行随机采样来初始化路由对数$b_{ij}$，让初始兴趣胶囊与其他每一个不同，其实就是希望在计算每个输出胶囊的时候，通过随机化的方式，希望这几个聚类中心离得远一点，这样才能表示出广泛的用户兴趣(我们已经了解这个机制就仿佛是聚类，而计算过程就是寻找聚类中心)。
3. **动态的兴趣数量**，兴趣数量就是聚类中心的个数，由于不同用户的历史行为序列不同，那么相应的，其兴趣胶囊有可能也不一样多，所以这里使用了一种启发式方式自适应调整聚类中心的数量，即$K$值。
$$
K_{u}^{\prime}=\max \left(1, \min \left(K, \log _{2}\left(\left|\mathcal{I}_{u}\right|\right)\right)\right)
$$
这种调整兴趣胶囊数量的策略可以为兴趣较小的用户节省一些资源，包括计算和内存资源。这个公式不用多解释，与行为序列长度成正比。

最终的B2I动态路由算法如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/37cc4943b91c494d987a8aa844077c42.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center)

- **Label-aware Attention Layer**
  通过多兴趣提取器层，从用户的行为embedding中生成多个兴趣胶囊。不同的兴趣胶囊代表用户兴趣的不同方面，相应的兴趣胶囊用于评估用户对特定类别的偏好。所以，在训练的期间，最后需要设置一个Label-aware的注意力层，对于当前的商品，根据相关性选择最相关的兴趣胶囊。这里其实就是一个普通的注意力机制，和DIN里面的那个注意力层基本上是一模一样，计算公式如下：
$$
\begin{aligned}
\overrightarrow{\boldsymbol{v}}_{u} &=\operatorname{Attention}\left(\overrightarrow{\boldsymbol{e}}_{i}, \mathrm{~V}_{u}, \mathrm{~V}_{u}\right) \\
&=\mathrm{V}_{u} \operatorname{softmax}\left(\operatorname{pow}\left(\mathrm{V}_{u}^{\mathrm{T}} \overrightarrow{\boldsymbol{e}}_{i}, p\right)\right)
\end{aligned}
$$
  首先这里的$\overrightarrow{\boldsymbol{e}}_{i}$表示当前的商品向量，$V_u$表示用户的多兴趣向量组合，里面有$K$个向量，表示用户的$K$的兴趣。用户的各个兴趣向量与目标商品做内积，然后softmax转成权重，然后反乘到多个兴趣向量进行加权求和。 但是这里需要注意的一个小点，就是这里做内积求完相似性之后，先做了一个指数操作，**这个操作其实能放大或缩小相似程度**，至于放大或者缩小的程度，由$p$控制。 比如某个兴趣向量与当前商品非常相似，那么再进行指数操作之后，如果$p$也很大，那么显然这个兴趣向量就占了主导作用。$p$是一个可调节的参数来调整注意力分布。当$p$接近0，每一个兴趣胶囊都得到相同的关注。当$p$大于1时，随着$p$的增加，具有较大值的点积将获得越来越多的权重。考虑极限情况，当$p$趋近于无穷大时，注意机制就变成了一种硬注意，选关注最大的值而忽略其他值。在实验中，发现使用硬注意导致更快的收敛。
>理解：$p$小意味着所有的相似程度都缩小了， 使得之间的差距会变小，所以相当于每个胶囊都会受到关注，而越大的话，使得各个相似性差距拉大，相似程度越大的会更大,最终使得只关注于比较大的胶囊。

### SDM模型
==先把长序列分成了多个会话， 然后把最近的一次会话，和之前的会话分别视为了用户短期行为和长期行为分别进行了建模，并采用不同的措施学习用户的短期兴趣和长期兴趣，然后通过一个门控机制融合得到用户最终的表示向量==

- **问题定义**:
$\mathcal{U}$表示用户集合，$\mathcal{I}$表示item集合，模型考虑在时间$t$，是否用户$u$会对$i$产生交互。 对于$u$，能够得到它的历史行为序列，下面是会话划分的规则：
1. 相同会话ID的商品(后台能获取)算是一个会话
2. 相邻的商品，时间间隔小于10分钟(业务自己调整)算一个会话
3. 同一个会话中的商品不能超过50个，多出来的放入下一个会话

这样划分开会话之后， 对于用户$u$的短期行为定义是离目前最近的这次会话， 用$\mathcal{S}^{u}=\left[i_{1}^{u}, \ldots, i_{t}^{u}, \ldots, i_{m}^{u}\right]$表示，$m$是序列长度。 而长期的用户行为是过去一周内的会话，但不包括短期的这次会话， 这个用$\mathcal{L}^{u}$表示。网络推荐架构如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/841c97c541484f908282be881ec32fd8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center)

- **Input Embedding with side Information**
在淘宝的推荐场景中，顾客与物品产生交互行为时，不仅考虑特定的商品本身，还考虑产品，商铺，价格等。所以，对于一个商品来说，不仅要用到Item ID，还用了更多的side info信息，包括`feat category, fist level category, brand,shop`。 

  假设用户的短期行为是 $\mathcal{S}^{u}=\left[i_{1}^{u}, \ldots, i_{t}^{u}, \ldots, i_{m}^{u}\right]$， 这里面的每个商品$i_t^u$ 有5个属性表示，每个属性本质是ID，但转成embedding之后，就得到了5个embedding。 这里用 $\boldsymbol{e}_{{i}^u_t} \in \mathbb{R}^{d \times 1}$ 来表示每个$i_t^u$，但这里不是embedding的pooling操作，而是Concat
$$
\boldsymbol{e}_{i_{t}^{u}}=\operatorname{concat}\left(\left\{\boldsymbol{e}_{i}^{f} \mid f \in \mathcal{F}\right\}\right)
$$
其中，$\boldsymbol{e}_{i}^{f}=\boldsymbol{W}^{f} \boldsymbol{x}_{i}^{f} \in \mathbb{R}^{d_{f} \times 1}$。这里embedding的维度是$d_f$， 等拼接起来之后，就是$d$维了。

  另外就是用户的base表示向量了,就是用户的基础画像，得到embedding，直接是Concat：
$$
\boldsymbol{e}_{u}=\operatorname{concat}\left(\left\{\boldsymbol{e}_{u}^{p} \mid p \in \mathcal{P}\right\}\right)
$$
$e_u^p$是特征$p$的embedding。

下面是整体的模型结构
![在这里插入图片描述](https://img-blog.csdnimg.cn/d297bf36d8c54b349dc666259b891927.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57-75rua55qE5bCPQOW8ug==,size_2,color_FFFFFF,t_70,g_se,x_16#pic_center)

- **短期用户行为建模**
  这里短期用户行为是下面的那个框， 接收的输入，首先是用户最近的那次会话，里面各个商品加入了side info信息之后，有了最终的embedding表示$\left[\boldsymbol{e}_{i_{1}^{u}}, \ldots, \boldsymbol{e}_{i_{t}^{u}}\right]$。 

  首先过LSTM学习序列信息：
$$
\begin{aligned}
\boldsymbol{i} \boldsymbol{n}_{t}^{u} &=\sigma\left(\boldsymbol{W}_{i n}^{1} \boldsymbol{e}_{i_{t}^{u}}+\boldsymbol{W}_{i n}^{2} \boldsymbol{h}_{t-1}^{u}+b_{i n}\right) \\
f_{t}^{u} &=\sigma\left(\boldsymbol{W}_{f}^{1} \boldsymbol{e}_{i_{t}^{u}}+\boldsymbol{W}_{f}^{2} \boldsymbol{h}_{t-1}^{u}+b_{f}\right) \\
\boldsymbol{o}_{t}^{u} &=\sigma\left(\boldsymbol{W}_{o}^{1} \boldsymbol{e}_{i}^{u}+\boldsymbol{W}_{o}^{2} \boldsymbol{h}_{t-1}^{u}+b_{o}\right) \\
\boldsymbol{c}_{t}^{u} &=\boldsymbol{f}_{t} \boldsymbol{c}_{t-1}^{u}+\boldsymbol{i} \boldsymbol{n}_{t}^{u} \tanh \left(\boldsymbol{W}_{c}^{1} \boldsymbol{e}_{i_{t}^{u}}+\boldsymbol{W}_{c}^{2} \boldsymbol{h}_{t-1}^{u}+b_{c}\right) \\
\boldsymbol{h}_{t}^{u} &=\boldsymbol{o}_{t}^{u} \tanh \left(\boldsymbol{c}_{t}^{u}\right)
\end{aligned}
$$
这里采用的是多输入多输出， 即每个时间步都会有一个隐藏状态$h_t^u$输出出来，那么经过LSTM之后，原始的序列就有了序列相关信息，得到了$\left[\boldsymbol{h}_{1}^{u}, \ldots, \boldsymbol{h}_{t}^{u}\right]$, 把这个记为$\boldsymbol{X}^{u}$。这里的$\boldsymbol{h}_{t}^{u} \in \mathbb{R}^{d \times 1}$表示时间$t$的序列偏好表示。

  接下来， 过Multi-head self-attention层,这个东西可以学习到$h_i^u$系列之间的相关性
$$
\text { head }{ }_{i}^{u}=\operatorname{Attention}\left(\boldsymbol{W}_{i}^{Q} \boldsymbol{X}^{u}, \boldsymbol{W}_{i}^{K} \boldsymbol{X}^{u}, \boldsymbol{W}_{i}^{V} \boldsymbol{X}^{u}\right)
$$
得到权重后，对原始的向量加权融合。 让$Q_{i}^{u}=W_{i}^{Q} X^{u}$， $K_{i}^{u}=W_{i}^{K} \boldsymbol{X}^{u}$，$V_{i}^{u}=W_{i}^{V} X^{u}$， 背后计算是：
$$
\begin{aligned}
&f\left(Q_{i}^{u}, K_{i}^{u}\right)=Q_{i}^{u T} K_{i}^{u} \\
&A_{i}^{u}=\operatorname{softmax}\left(f\left(Q_{i}^{u}, K_{i}^{u}\right)\right)
\end{aligned} \\ \operatorname{head}_{i}^{u}=V_{i}^{u} A_{i}^{u T}
$$
这是一个头的计算， 接下来每个头都这么算，假设有$h$个头，这里会通过上面的映射矩阵$W$系列，先把原始的$h_i^u$向量映射到$d_{k}=\frac{1}{h} d$维度，然后计算$head_i^u$也是$d_k$维，这样$h$个head进行拼接，正好是$d$维， 接下来过一个全连接或者线性映射得到MultiHead的输出。
$$
\hat{X}^{u}=\text { MultiHead }\left(X^{u}\right)=W^{O} \text { concat }\left(\text { head }_{1}^{u}, \ldots, \text { head }_{h}^{u}\right)
$$
得到这个东西之后，接下来再过一个User Attention，因为对于相似历史行为的不同用户，其兴趣偏好也不太一样。
所以加入这个用户Attention层，想挖掘**更细粒度**的用户个性化信息。用户的base向量$e_u$作为query，与$\hat{X}^{u}$的每个向量做Attention，然后加权求和得最终向量：
$$
\begin{aligned}
\alpha_{k} &=\frac{\exp \left(\hat{\boldsymbol{h}}_{k}^{u T} \boldsymbol{e}_{u}\right)}{\sum_{k=1}^{t} \exp \left(\hat{\boldsymbol{h}}_{k}^{u T} \boldsymbol{e}_{u}\right)} \\
\boldsymbol{s}_{t}^{u} &=\sum_{k=1}^{t} \alpha_{k} \hat{\boldsymbol{h}}_{k}^{u}
\end{aligned}
$$
其中$s_{t}^{u} \in \mathbb{R}^{d \times 1}$

- **用户长期行为建模**
从长期的视角看，用户在不同的维度上可能积累了广泛的兴趣，用户可能经常访问一组类似的商店，并反复购买属于同一类别的商品。所以长期行为$\mathcal{L}^{u}$来自于不同的特征尺度。
$$
\mathcal{L}^{u}=\left\{\mathcal{L}_{f}^{u} \mid f \in \mathcal{F}\right\}
$$
这里面包含了各种side特征。长期行为是从特征的维度进行聚合，也就是**把用户的历史长序列分成了多个特征**，比如用户历史点击过的商品，历史逛过的店铺，历史看过的商品的类别，品牌等，分成了多个特征子集，然后这每个特征子集里面有对应的id，比如商品有商品id, 店铺有店铺id等，对于每个子集，过user Attention layer，和用户的base向量求Attention， 得到每个子集最终的表示向量。每个子集的计算过程如下：
$$
\begin{aligned}
\alpha_{k} &=\frac{\exp \left(\boldsymbol{g}_{k}^{u T} \boldsymbol{e}_{u}\right)}{\sum_{k=1}^{\left|\mathcal{L}_{f}^{u}\right|} \exp \left(\boldsymbol{g}_{k}^{u T} \boldsymbol{e}_{u}\right)} \\
z_{f}^{u} &=\sum_{k=1}^{\left|\mathcal{L}_{f}^{u}\right|} \alpha_{k} \boldsymbol{g}_{k}^{u}
\end{aligned}
$$
每个子集都会得到一个加权的向量，把这个东西拼起来，然后过DNN。
$$
\begin{aligned}
&z^{u}=\operatorname{concat}\left(\left\{z_{f}^{u} \mid f \in \mathcal{F}\right\}\right) \\
&\boldsymbol{p}^{u}=\tanh \left(\boldsymbol{W}^{p} z^{u}+b\right)
\end{aligned}
$$
这里的$\boldsymbol{p}^{u} \in \mathbb{R}^{d \times 1}$， 这样就得到了用户的长期兴趣表示。
- **短长期兴趣融合**
长短期兴趣融合这里，作者发现之前模型往往喜欢直接拼接起来，或者加和，注意力加权等，但作者认为这样不能很好的将两类兴趣融合起来，因为长期序列里面，其实**只有很少的一部分行为和当前有关**。那么这样的话，直接无脑融合是有问题的。所以这里作者用了一种较为巧妙的方式，即门控机制：
$$
G_{t}^{u}=\operatorname{sigmoid}\left(\boldsymbol{W}^{1} \boldsymbol{e}_{u}+\boldsymbol{W}^{2} s_{t}^{u}+\boldsymbol{W}^{3} \boldsymbol{p}^{u}+b\right) \\ 
o_{t}^{u}=\left(1-G_{t}^{u}\right) \odot p^{u}+G_{t}^{u} \odot s_{t}^{u}
$$
这个和LSTM的这种门控机制很像，首先门控接收的输入有用户画像$e_u$，用户短期兴趣$s_t^u$， 用户长期兴趣$p^u$，经过sigmoid函数得到了$G_{t}^{u} \in \mathbb{R}^{d \times 1}$，用来决定在$t$时刻短期和长期兴趣的贡献程度。然后根据这个贡献程度对短期和长期偏好加权进行融合。

  最终得到的短期或者长期兴趣都是$d$维的向量， 每一个维度可能代表着不同的兴趣偏好，比如第一维度代表品牌，第二个维度代表类别，第三个维度代表价格，第四个维度代表商店等等。

  那么如果直接相加或者是加权相加，其实都意味着长短期兴趣的每个维度都有很高的保留，但万一长期兴趣和短期兴趣维度冲突了呢？ 比如短期兴趣里面可能用户喜欢这个品牌，长期用户里面用户喜欢那个品牌，那么听谁的？可能说短期兴趣这个占更大权重呗，那么普通加权可是所有向量都加的相同的权重，品牌这个维度听短期兴趣的，其他维度比如价格，商店也都听短期兴趣的？本身存在不合理性。那么反而直接相加或者加权效果会不好。

  而门控机制的巧妙就在于，给每个维度都学习到一个权重，而这个权重非0即1，接下来融合时，通过这个门控机制，取长期和短期兴趣向量每个维度上的其中一个。比如在品牌方面听谁的，类别方面听谁的，价格方面听谁的，**只会听短期和长期兴趣的其中一个**。这样就不会有冲突发生，而至于具体听谁的，交给网络自己学习。这样就使得用户长期兴趣和短期兴趣融合的时候，每个维度上的信息保留变得**有选择**。使得兴趣的融合方式更加的灵活。

 ==这其实又提供了一种两个向量融合的一种新思路，并不一定非得加权或者拼接或者相加了，还可以通过门控机制让网络自己学==