# 基于协同过滤的召回
## Use-CF & Item-CF

**示例图片**
![image-20210629232622758](http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20210629232622758.png)

### user

**计算过程**
1. 计算用户之间的相似度

   + 根据几种评价指标,计算出各用户之间的相似程度。对于用户 Alice，选取出与其最相近的 $N$ 个用户。

2. 计算用户对新物品的评分预测

   + 方法一：利用目标用户与相似用户之间的相似度以及相似用户对物品的评分，来预测目标用户对候选物品的评分估计：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot R_{\mathrm{s}, \mathrm{p}}\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，权重 $w_{u,s}$ 是用户 $u$ 和用户 $s$ 的相似度， $R_{s,p}$ 是用户 $s$ 对物品 $p$ 的评分。

   + 方法二：考虑到用户评分的偏置，即有的用户喜欢打高分， 有的用户喜欢打低分的情况。公式如下：
     $$
     R_{\mathrm{u}, \mathrm{p}}=\bar{R}_{u} + \frac{\sum_{\mathrm{s} \in S}\left(w_{\mathrm{u}, \mathrm{s}} \cdot \left(R_{s, p}-\bar{R}_{s}\right)\right)}{\sum_{\mathrm{s} \in S} w_{\mathrm{u}, \mathrm{s}}}
     $$

     + 其中，$\bar{R}_{s}$ 表示用户 $s$ 对物品的历史平均评分。

3. 对用户进行物品推荐

   + 在获得用户 $u$ 对不同物品的评价预测后， 最终的推荐列表根据预测评分进行排序得到。 

### item

计算过程
1. 计算物品之间的相似度：余弦相似性或者皮尔逊相关系数。选取TopN相似物品计算评分
2. 根据选取出来的TopN，与user的计算方式相同，计算得分。

由于物品推荐存在长尾效应，需要对推荐权重进行控制，以防止推荐内容过于同质化。

* base 公式
  $$
  w_{i j}=\frac{|N(i) \bigcap N(j)|}{|N(i)|}
  $$

  + 该公式表示同时喜好物品 $i$ 和物品 $j$ 的用户数，占喜爱物品 $i$ 的比例。
  + 缺点：若物品 $j$ 为热门物品，那么它与任何物品的相似度都很高。

* 控制对热门物品的惩罚力度
  $$
  w_{i j}=\frac{|N(i) \cap N(j)|}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
  $$

  * 参数 $\alpha$为可控惩罚力度。

* 对活跃用户的惩罚

  * 在计算物品之间的相似度时，可以进一步将用户的活跃度考虑进来。
    $$
    w_{i j}=\frac{\sum_{\operatorname{\text {u}\in N(i) \cap N(j)}} \frac{1}{\log 1+|N(u)|}}{|N(i)|^{1-\alpha}|N(j)|^{\alpha}}
    $$

### 弊端
1. 泛化能力弱，无法将两个物品的相似信息推广到其他物品上，进而导致热门物品具有**很强的头部效应**，容易跟大量物品产生相似，而尾部物品由于特征向量稀疏，导致很少被推荐，也就是推荐时的同质化。
2. 需要考虑用户评分倾向，一部分用户倾向高分，一部分用户倾向低分。需要对相似度计算进行改进，否则会造成错误分类
3. 没有利用更多的用户或者物品信息，只使用交互信息进行计算，整体模型的表达能力十分有限。

## 矩阵分解

+ 原理图：
<img src="https://img-blog.csdnimg.cn/20200822212051499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />

+ 基本思想
  - 用户矩阵Q
    表示不同用户**对于不同元素的偏好程度**，取值范围[0,1]，1代表很喜欢，0代表不喜欢。
  - 物品矩阵P
    表示**每种物品含有各种元素（特征）的成分**
  - 计算：
    通过将对应向量的元素做内积运算，得到用户对该物品的喜好程度。相应的可以得到用户对每个物品的评分矩阵

+ FunkSVD with Bias 算法
  - 思想：**把求解P、Q的参数问题转换成最优化问题，通过训练集里面的观察值,利用最小化来学习用户矩阵和物品矩阵。**
  - 算法过程
  1. 在有用户矩阵和物品矩阵的前提下，若要计算用户 $u$ 对物品 $i$ 的评分， 可以根据公式：
   $$
   \operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{k=1}^{K} p_{u, k} q_{i,k}
   $$
   其中，向量 $p_u$ 表示用户 $u$ 的隐向量，向量  $q_i$ 表示物品 $i$ 的隐向量。

  2. **随机初始化**一个用户矩阵 $U$ 和一个物品矩阵 $V$，获取每个用户和物品的初始隐语义向量。一般是与`1/sqrt(F)`成正比，F为隐向量维度。

  3. 计算预测得分 with bias
   $$\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}$$.其中，$\mu$反映推荐模型整体的平均评分，一般为样本均值；$b_u$为用户偏差系数。可以使用用户 $u$ 的评分均值，也可作为训练参数；$b_i$为物品偏差系数。可以使用物品 $i$ 的得分均值，也可以当做训练参数。

  4. 对于评分矩阵中的每个元素，计算预测误差 $e_{u i}=r_{u i}-\hat{r}_{u i}$，对所有训练样本的平方误差进行累加：
   $$
   \operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)^{2}
   $$为方便后续求解，给 $SSE$ 增加系数 $1/2$ ：
     $$
     \operatorname{SSE}=\frac{1}{2} \sum_{u, i} e_{u i}^{2}=\frac{1}{2} \sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u k} q_{i k}\right)^{2}
     $$

  5.  前面提到，模型预测越准确等价于预测误差越小，那么优化的目标函数变为：
  $$
  \begin{aligned}
  \min _{q^{*}, p^{*}} \frac{1}{2} \sum_{(u, i) \in K} &\left(r_{u i}-\left(\mu+b_{u}+b_{i}+q_{i}^{T} p_{u}\right)\right)^{2} \\
  &+\lambda\left(\left\|p_{u}\right\|^{2}+\left\|q_{i}\right\|^{2}+b_{u}^{2}+b_{i}^{2}\right)
  \end{aligned}
  $$ 
  $K$ 表示所有用户评分样本的集合，**即评分矩阵中不为空的元素**，其他空缺值在测试时是要预测的。该目标函数需要优化的目标是用户矩阵 $U$ 和一个物品矩阵 $V$。

  1. 对于给定的目标函数，可以通过梯度下降法对参数进行优化。

   + 求解目标函数 $SSE$ 关于用户矩阵中参数 $p_{u,k}$ 的梯度：
     $$
     \frac{\partial}{\partial p_{u,k}} S S E=\frac{\partial}{\partial p_{u,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial p_{u,k}} e_{u i}=e_{u i} \frac{\partial}{\partial p_{u,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} q_{i,k}
     $$

   + 求解目标函数 $SSE$ 关于 $q_{i,k}$ 的梯度：
     $$
     \frac{\partial}{\partial q_{i,k}} S S E=\frac{\partial}{\partial q_{i,k}}\left(\frac{1}{2}e_{u i}^{2}\right) =e_{u i} \frac{\partial}{\partial q_{i,k}} e_{u i}=e_{u i} \frac{\partial}{\partial q_{i,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{i,k}\right)=-e_{u i} p_{u,k}
     $$

  2. 参数梯度更新
   $$
   p_{u, k}=p_{u,k}-\eta (-e_{ui}q_{i, k})=p_{u,k}+\eta e_{ui}q_{i, k} \\ 
   q_{i, k}=q_{i,k}-\eta (-e_{ui}p_{u,k})=q_{i, k}+\eta e_{ui}p_{u, k}\\
   \frac{\partial}{\partial b_{i}} S S E=-e_{u i}+\lambda b_{i}\\
   \frac{\partial}{\partial b_{u}} S S E=-e_{u i} +\lambda b_{u}
   $$ 其中，$\eta$ 表示学习率，用于控制步长。当**参数很多**的时候，就是两个矩阵很大的时候，往往容易陷入**过拟合**的困境，需要在目标函数上面加上正则化的损失。

  - 原理图，==分解出的k维特征是模型待学习的参数==
<div align=center>
<img src="https://img-blog.csdnimg.cn/20200823101513233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1emhvbmdxaWFuZw==,size_1,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:70%;" />
</div>

## Neural Collaborative Filtering (NeuralCF)

### 模型结构
<div align="center">
  <img src="https://static001.geekbang.org/resource/image/5f/2c/5ff301f11e686eedbacd69dee184312c.jpg" alt="NeuralCF Model" style="zoom:33%;">
</div>

### 原理
- **输入特征**：用户ID和项目ID转换为OneHot向量，并映射成指定维度的稠密向量，解决冷启动问题。
- **GMF（广义矩阵分解部分）**：用户与物品特征矩阵逐元素点积，通过线性方法学习特征。
- **MLP**：设置用户和物品的MLP，通过特征组合拼接embedding，经过线性层得到MLP的输出。
- **最终输出**：拼接GMF与MLP特征，通过线性层得到最终输出。

### 优化
$$
L_{sqr}=\sum_{(u,i)\in y\cup y^-}w_{ui}(y_{ui}-\hat{y}_{ui})^2
$$
其中 $w_{ui}$ 为超参数，给每个样本赋权重。

$$
p(y,y^-|P,Q,\Theta_f)=\prod_{(u,i)\in{y}}\hat{y}_{ui}\prod_{(u,j)\in{y^-}}(1-\hat{y}_{uj})
$$

$$
L=-\sum_{(u,i)\in{y}}log\hat{y}_{ui}-\sum_{(u,j)\in{y^-}}log(1-\hat{y}_{uj})=-\sum_{(u,i)\in{y}\cup{y}^-}y_{ui}log \hat{y}_{ui}+(1-y_{ui})log(1-\hat{y}_{ui})
$$
使用随机梯度下降（SGD）进行训练优化。这个函数等价于交叉熵损失函数(binary cross-entropy loss)。通过对NCF进行概率处理，将隐性反馈的推荐问题当做二分类问题来解决。对于负样本 $y^-$，每次迭代均匀地从未观察到交互作用中采样作为负样本，控制采样比例。

**注**：MF是NCF模型的一个特例。

# 基于向量召回
## FM模型（分解机）

### 模型形式

$$
y = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n}\sum_{i+1}^n\lt v_i,v_j\gt x_ix_j
$$

改进思想：**为每个 $x_i$ 计算一个 embedding，然后将两个向量之间的 embedding 做内积得到之前所谓的 $w_{ij}$**。这使得即使两个特征之前从未在训练集中**同时**出现，只需要 $x_i$ 和其他的 $x_k$ 同时出现过就可以计算出 $x_i$ 的 embedding，大大提升了模型的泛化能力。**当交叉项参数 $w_{ij}$ 全为 0 的时候，整个模型就退化为普通的 LR 模型**。

---

公式中各参数的意义：

- $\omega_{0}$：**全局偏置**；
- $\omega_{i}$：模型第 $i$ 个变量的权重；
- $\omega_{ij} = < v_{i}, v_{j}>$：特征 $i$ 和 $j$ 的交叉权重；
- $v_{i}$：第 $i$ 维特征的隐向量；
- $<\cdot, \cdot>$：向量点积；
- $k(k<<n)$：隐向量的长度，包含 $k$ 个描述特征的因子。

---

* 降低时间复杂度的证明

利用 $\sum$ 运算的线性性质，公式可以化简为：

$$
\begin{align} 
\sum_{i=1}^{n-1}{\sum_{j=i+1}^{n}{<v_i,v_j>x_ix_j}}
&= \frac{1}{2}\sum_{i=1}^{n}{\sum_{j=1}^{n}{<v_i,v_j>x_ix_j}} - \frac{1}{2} {\sum_{i=1}^{n}{<v_i,v_i>x_ix_i}} \\
&= \frac{1}{2} \left( \sum_{i=1}^{n}{\sum_{j=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{j,f}x_ix_j}}} - \sum_{i=1}^{n}{\sum_{f=1}^{k}{v_{i,f}v_{i,f}x_ix_i}} \right) \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right) \cdot \left( \sum_{j=1}^{n}{v_{j,f}x_j} \right) - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} \\
&= \frac{1}{2}\sum_{f=1}^{k}{\left[ \left( \sum_{i=1}^{n}{v_{i,f}x_i} \right)^2 - \sum_{i=1}^{n}{v_{i,f}^2 x_i^2} \right]} 
\end{align}
$$

---

* 解释

- $v_{i,f}$ 是一个具体的值；
- **第 1 个等号**：对称矩阵 $W$ 的对角线上半部分；
- **第 2 个等号**：将向量内积 $<v_i, v_j>$ 展开为累加和的形式；
- **第 3 个等号**：提出公共部分；
- **第 4 个等号**：$i$ 和 $j$ 相当于表示为相同的平方过程。

### 用于召回的改进

## item2vec召回

### word2vec方法

- **one-hot编码的缺陷**：
  1. 矩阵稀疏，尤其是当特征数量很大的时候
  2. 构成的词向量为正交运算，无法通过数学运算计算词之间的相似性

- **word2Vec算法**：
  1. 使用大量文本预料库
  2. 构建的词汇表中，每一个单词都由宇哥词向量表示
  3. 遍历文本的每一个位置t，都有中心词c与上下文词o(outside)
  4. 再整个语料库上，使用数学方法，最大化o在单词c周围出现的概率，进而得到每一个单词的dense表示
  5. 迭代更新，直到达到最佳效果
   
  - 模型结构
  - 
  输入为1 X V维的one-hot向量（V为整个词汇表的长度，这个向量只有一个1值，其余为0值表示一个词），单隐藏层（隐藏层的维度为N，这里是一个超参数，也就是词向量的维度），输出为1 X V维的softmax层的模型。$W^{I}$为V X N的参数矩阵，$W^{O}$为N X V的参数矩阵

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片8.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **Skip-gram模型**
  - 目的：最大化单词o在单词c周围出现的概率，也就是\(arg max P(o|c)\).通过设置窗口大小来控制考虑的元素。具体如下如图所示。通过设置窗口为2，然后不断滑动窗口，也从而得到了所有位置元素的概率值。

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片3.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

  - 求解：极大似然法 $ max\prod_{c} \prod_{o}P(o|c) $， 也就是
  \(\prod_{t=1}^{T} \prod_{\substack{j=-m \\ j\neq0}}^{m} P(w_{t+j}|w_t;\theta)\), 
  对整体的函数取log，并加负号。得到最终的损失函数：\(\frac{1}{T} \sum_{t=1}^{T} \sum_{\substack{j=-m \\ j \neq 0}}^{m} \log p(w_{t+j}|w_t+\theta)\)
  
  - \(P(o|c)\)计算：使用中心词c与上下文词o的相似性计算，使用向量的点积表示$u_o \cdot v_c$，然后使用softmax函数映射成一个概率值，如下。每个词都会有两个词向量，一个是自己作为中心词的向量，一个是自己作为上下文词的向量。
  
  $$
  \frac{1}{T} \sum_{t=1}^{T} \sum_{\substack{j=-m \\ j \neq 0}}^{m} \log p(w_{t+j}|w_t+\theta)
  $$

  - 结构：
    ==给定中心词，预测周围的词==

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220424105817437.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **CBOW**
  - 模型结构
  
  == 给定周围词，预测中心词==

  <div align=center>
  <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片10.png" alt="在这里插入图片描述" style="zoom:50%;" /> 
  </div>

- **负采样**
  - softmax的问题：分母需要在整个单词表上计算乘积与指数运算，计算资源消耗很大。
  - 负采样：
  损失函数如下，其中$\sigma$为sigmoid函数$1/(1+e^{-x})$，$u_{o}$为实际样本中的上下文词的词向量，而$u_{k}$为按一定的规则随机选出的K个单词。由单调性规则，$u_{o}^T \cdot v_c$越大，损失函数越小，而$u_{k}^T \cdot v_c$越小，损失函数越大

  $$
  J_{neg_{sample}}(b_{u_o}, v_c, U) = -\log \sigma({u_o}^Tv_C) - \sum_{k\in K(\text{sampled indices})} \log \sigma(-u_k^Tv_C)
  $$
  - 单词 $w$ 作为负样本时，被采样到的概率：
  
  $$
  \frac{[\operatorname{counter}(w)]^{0.75}}{\sum_{u \in \mathcal{W}}[\operatorname{counter}(u)]^{0.75}}
  $$

  - 单词 $w$ 作为中心词时，被丢弃的概率：
  - 
  $$
  \operatorname{prob}(w)=1-\sqrt{\frac{t}{f(w)}}
  $$

  - 关于$v_c$的导数：

  $$ 
  \begin{aligned}
  \frac{\partial J_{\text{neg-sample}}(\boldsymbol v_c, o, \boldsymbol U)}{\partial \boldsymbol v_c} &= -\frac{\sigma(\boldsymbol u_o^T \boldsymbol v_c)(1 - \sigma(\boldsymbol u_o^T \boldsymbol v_c))}{\sigma(\boldsymbol u_o^T \boldsymbol v_c)} \frac{\partial (\boldsymbol u_o^T \boldsymbol v_c)}{\partial \boldsymbol v_c} - \sum_{k=1}^{K} \frac{\partial \log(\sigma(-\boldsymbol u_k^T \boldsymbol v_c))}{\partial \boldsymbol v_c}\\ &= -(1 - \sigma(\boldsymbol u_o^T \boldsymbol v_c)) \boldsymbol u_o + \sum_{k=1}^{K} (1 - \sigma(-\boldsymbol u_k^T \boldsymbol v_c)) \boldsymbol u_k
  \end{aligned}
  $$

### item2Vec召回

- **原理**：基于物品集合进行训练，丢弃物品的时间与空间信息。同时，假设对于一个集合的物品，它们之间是相似的，与用户购买它们的顺序、时间无关。

- **目标函数**：
$$
\frac{1}{K} \sum_{i=1}^{K} \sum_{j \neq i}^{K} \log p\left(w_{j} \mid w_{i}\right)
$$

- **相似度计算**：使用余弦相似度
- **问题**：计算不同物品之间的相似度时，仍然会依赖不同物品之间的共性，无法解决冷启动问题。一种解决方法是取出与冷启物品类别相同的非冷启物品，将它们向量的均值作为冷启动物品的向量表示。

## Airbnb召回

### Embedding方法
1. 用于描述短期实时性的个性化特征 Embedding：listing Embeddings（listing代表房源）
   - 学习来源：通过用户的点击对话学习特征，表示房源的短期实时特征。给定数据集 $ \mathcal{S} $ ，其中包含了 $ N $ 个用户的 $ S $ 个点击 session（序列）。

     - 每个 session $ s=\left(l_{1}, \ldots, l_{M}\right) \in \mathcal{S} $ ，包含了 $ M $ 个被用户点击过的 listing ids 。
     - 对于用户连续两次点击，若时间间隔超过了30分钟，则启动新的 session。
   - 优化：在得到多个用户点击的session之后，基于word2Vec的SkipGram模型学习不同的listing embedding表示。最大化目标函数：
    $$ 
    \mathcal{L}=\sum_{s \in \mathcal{S}} \sum_{l_{i} \in s}\left(\sum_{-m \geq j \leq m, i \neq 0} \log \mathbb{P}\left(l_{i+j} \mid l_{i}\right)\right) 
    $$
    其中，$\mathbb{P}\left(l_{i+j} \mid l_{i}\right)$ 基于softmax函数，表示一个session中，已知中心listing $l_i$ 来预测上下文 listing $l_{i+j}$ 的概率，也就是：
    $$ 
    \mathbb{P}\left(l_{i+j} \mid l_{i}\right)=\frac{\exp \left(\mathbf{v}{l{i}}^{\top} \mathbf{v}{l{i+j}}^{\prime}\right)}{\sum_{l=1}^{|\mathcal{V}|} \exp \left(\mathbf{v}{l{i}}^{\top} \mathbf{v}_{l}^{\prime}\right)} $$
    其中， $ \mathbf{v}{l{i}} $ 表示 listing $ l_i $ 的 Embedding 向量， $ |\mathcal{V}| $ 表示全部的物料库的数量。由于物料库过大，需要做负采样处理，负采样的目标函数为：
    $$ 
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}{p}} \log \frac{1}{1+e^{-\mathbf{v}{c}^{\prime^{\prime}} \mathbf{v}{l}}}+\sum{(l, c) \in \mathcal{D}{n}} \log \frac{1}{1+e^{\mathbf{v}{c}^{\prime} \mathbf{v}_{l}}} 
    $$ 
    - 正负样本集构建
      - 使用 booked listing 作为全局上下文。booked listing 表示用户在 session 中最终预定的房源，一般只会出现在结束的 session 中。
      - Airbnb 将最终预定的房源，始终作为滑窗的上下文，即**全局上下文**。如下图，对于当前滑动窗口的 central listing，实线箭头表示context listings，虚线（指向booked listing）表示 global context listing。

    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片1653053823336-0564b2da-c993-46aa-9b22-f5cbb784dae2.png" alt="img" style="zoom:50%;" />

    - booked listing 作为全局正样本，故优化的目标函数更新为：

    $$
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}_{p}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime^{\prime}} \mathbf{v}_{l}}}+\sum_{(l, c) \in \mathcal{D}_{n}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{l}}} +
    \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{l_b}}}
    $$

    - 优化负样本的选择
      - 用户通过在线网站预定房间时，通常只会在同一个 market （将要停留区域）内进行搜索。
   
      - 对于用户点击过的样本集 $ \mathcal{D}_{p} $ （正样本集）而言，它们大概率位于**同一片区域**。考虑到负样本集 $ \mathcal{D}_{n} $ 是随机抽取的，大概率来源不同的区域。
   
      - Airbnb 发现这种样本的不平衡，在学习同一片区域房源的 Embedding 时会得到次优解。
   
      - 解决办法也很简单，对于每个滑窗中的中心 lisitng，其负样本的选择新增了**与其位于同一个 market 的 listing**。至此，优化函数更新如下：
     
    $$
    \underset{\theta}{\operatorname{argmax}} \sum_{(l, c) \in \mathcal{D}_{p}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime^{\prime}} \mathbf{v}_{l}}}+\sum_{(l, c) \in \mathcal{D}_{n}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{l}}} +\log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{l_b}}} + 
    \sum_{(l, m_n ) \in \mathcal{D}_{m_n}} \log \frac{1}{1+e^{\mathbf{v}_{m_n}^{\prime} \mathbf{v}_{l}}}
    $$ 

      - $ \mathcal{D}_{m_n} $ 表示与滑窗中的中心 listing 位于同一区域的负样本集。
      - 冷启动：根据房源信息，查找最相似的三个房源，用三个房源的均值作为新的房源的embedding表示。

2. 用于描述长期的个性化特征 Embedding：user-type & listing type Embeddings
   - 潜在问题：
     - 需要基于booking session进行学习，但是数据量很小，因为booking本身就是低频率时间
     - 如果用户只预定过单个数量的房源，则无法从该会话中学习到embedding信息。因为要学习有效的embedding，该实体必须至少出现五次以上。
     - booking的时间跨度会比较大，无法保证用户在这么长的时间跨度里兴趣是否发生变化。
   - 改进：定一个 booking sessions 集合 $\mathcal{S}_{b}$ ，其中包含了$M$个用户的 booking session：每个booking session表示为：$s_{b}=\left(l_{b 1}, \ldots, l_{b M}\right)$，$l_{b1}$ 表示 listing_id，学习到 Embedding 记作 $\mathbf{v}{l{i d}}$。也就是兼顾用户的个人信息与房源信息。
   - 训练过程
     - 图例：
      <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片1653131985447-e033cb39-235b-4f46-9634-3b7faec284be.png" alt="img" style="zoom:50%;" />

    - 联合训练 User-type Embedding 和 Listing-type Embedding
      - 如图（a），在 booking session 中，每个元素代表的是 User-type, Listing-type组合。
      - 为了学习在相同向量空间中的 User-type 和 Listing-type 的 Embeddings，Airbnb 的做法是将 User-type 插入到 booking sessions 中。
      - 形成一个（User-type, Listing-type）组成的元组序列，这样就可以让 User-type 和 Listing-type 的在 session 中的相对位置保持一致了。
      
   - User-type 的目标函数：
      
      $$
      \underset{\theta}{\operatorname{argmax}} \sum_{\left(u_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+e^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}+\sum_{\left(u_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+e^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}
      $$
   
      +  $ \mathcal{D}_{\text {book }} $ 中的 $ u_t $ （中心词）表示 User-type， $ c $ （上下文）表示用户最近的预定过的 Listing-type。 $ \mathcal{D}_{\text {neg}} $ 中的 $ c $ 表示 negative Listing-type。
      +  $ u_t $ 表示 User-type 的 Embedding， $ \mathbf{v}_{c}^{\prime} $ 表示 Listing-type 的Embedding。

   - Listing-type 的目标函数：
     
     $$
     \begin{aligned}
     \underset{\theta}{\operatorname{argmax}} & \sum_{\left(l_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}}+\sum_{\left(l_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}} \\
     \end{aligned}
     $$

     + 同理，不过窗口中的中心词为 Listing-type， 上下文为 User-type。

- Explicit Negatives for Rejections
   - 用户预定房源以后，还要等待房源主人的确认，主人可能接受或者拒绝客人的预定。拒接的原因可能包括，客人星级评定不佳，资料不完整等。
      
   - 前面学习到的 User-type Embedding 包含了客人的兴趣偏好，Listing-type Embedding 包含了房源的属性特征。但是，用户的 Embedding 未包含更容易被哪类房源主人拒绝的潜语义信息房源的 Embedding 未包含主人对哪类客人的拒绝偏好。
      
   - 为了提高用户预定房源以后，被主人接受的概率。同时，降低房源主人拒绝客人的概率。Airbnb 在训练 User-type 和 Listing-type 的 Embedding时，将用户预定后却被拒绝的样本加入负样本集中（如图b）。
      - 更新后，Listing-type 的目标函数：
        
        $$
        \begin{aligned}
        \underset{\theta}{\operatorname{argmax}} & \sum_{\left(u_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}}+\sum_{\left(u_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathbf{v}_{c}^{\prime} \mathbf{v}_{u_{t}}}} \\
        &+\sum_{\left(u_{t}, l_{t}\right) \in \mathcal{D}_{\text {reject }}} \log \frac{1}{1+\exp ^{\mathrm{v}_{{l_{t}}}^{\prime} \mathrm{v}_{u_{t}}}} 
        \end{aligned}
        $$
      
      - 更新后，User-type 的目标函数：
        
        $$
        \begin{aligned}
        \underset{\theta}{\operatorname{argmax}} & \sum_{\left(l_{t}, c\right) \in \mathcal{D}_{b o o k}} \log \frac{1}{1+\exp ^{-\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}}+\sum_{\left(l_{t}, c\right) \in \mathcal{D}_{n e g}} \log \frac{1}{1+\exp ^{\mathrm{v}_{c}^{\prime} \mathbf{v}_{l_{t}}}} \\
        &+\sum_{\left(l_{t}, u_{t}\right) \in \mathcal{D}_{\text {reject }}} \log \frac{1}{1+\exp ^{\mathrm{v}^{\prime}_{u_{t}} \mathrm{v}_{l_{t}}}}
        \end{aligned}
        $$

## YoutubeDNN推荐系统

### 挑战：
  1. Scale(规模): 视频数量非常庞大，大规模数据下需要分布式学习算法以及高效的线上服务系统，论文体现这一点的是召回模型线下训练的时候，采用了**负采样**的思路，线上服务的时候，采用了**hash映射**，然后近邻检索的方式来满足实时性的需求.
  2. Freshness(新鲜度):用户实时上传，且实时访问，最新的视频往往容易博得用户的眼球。为了让模型学习到用户对新视频有偏好，策略里面加了一个"example age"作为体现。
  3. Noise(噪声): 由于数据的稀疏和不可见的其他原因，数据里面的噪声非常多，需要让这个推荐系统变得鲁棒。这个涉及到召回和排序两块，召回上需要考虑更多实际因素，比如非对称消费特性，高活用户因素，时间因素，序列因素等，并采取了相应的措施， 而排序上做更加细致的特征工程， 尽量的刻画出用户兴趣以及视频的特征、优化训练目标，使用加权的逻辑回归等。召回和排序模型上，都采用了深度神经网络，通过特征的相互交叉，有了更强大的建模能力。

### 模型

- **结构**：
<div align=center>
<img src="https://img-blog.csdnimg.cn/1c5dbd6d6c1646d09998b18d45f869e5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:150%;" /> 
</div>

$$
\downarrow
$$

<div align=center>
<img src="https://img-blog.csdnimg.cn/aeae52971a1345a98b310890ea81be53.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:90%;" /> 
</div>

  - **召回侧**：==快速从海量物品中找到用户潜在感兴趣的物品==
    - 输入与输出：输入一般是用户的点击历史，以及人口统计学特征；输出是与用户相关的候选视频集合。
    - 召回方式：一种基于策略进行召回，也就是根据真实场景进行设定，取决于工作经验；另一种是监督模型 + embedding。

  - **精排侧**：==融入更多负责特征，使用复杂的模型进行精准个性化推荐==
    - 关键点：特征工程、模型设计、训练方法

- **召回侧细节**：
  在时刻$t$下， 用户$U$在背景$C$下对每个视频$i$的观看行为建模如下：
  $$
  P\left(w_{t}=i \mid U, C\right)=\frac{e^{v_{i} u}}{\sum_{j \in V} e^{v_{j} u}}
  $$

  结构如下。将用户观看历史视频的embedding、搜索记录、用户人文特征作为模型的input。经过DNN模型的特征组合与降维，得到用户向量。item向量使用w2v方法训练后得到embedding矩阵。
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/724ff38c1d6448399edb658b1b27e18e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>

- **训练数据选取与生成**：
  - 来源于全部的观看记录，以及从其他渠道观看的视频；
  - 正样本：将训练数据来源于用户的隐式数据（隐式数据指的是用户在平台上的行为数据，而不是直接的反馈（如评分或评论））并且看完的视频；
  - 负样本：从视频库中随机选取，或者将曝光的但是用户没有点击的视频作为负样本。
  - trick：1、训练数据应该对每个用户选取相同的样本数，确保每个用户对模型训练过程中的损失函数和权重的贡献是均衡的，避免**某些特别活跃的用户**在训练过程中对损失函数的影响过大，从而影响模型的训练效果；2、避免模型了解不该了解的信息，也就是消除数据的时序信息。
  - 滑动窗口：用于解决用户以及行为少的问题。通过设置滑动窗口，生成多条训练样本。例如一个用户的历史观看记录是"abcdef"，那么采用滑动窗口，可以是abc预测d, bcd预测e, cde预测f。理论基础是==非对称观看概率：用户开始浏览范围较广，之后浏览范围逐渐变窄==
  - 解决信息泄露：仅仅使用历史信息作为输入，不让模型接触到用户的未来行为。图a是大部分协同过滤的方法，选取全局观看信息作为模型输入，会造成信息穿越；图b为目前主流的数据构建方式。
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/049cbeb814f843fd97638ef02d6c5703.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_2,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>

  - Example Age 特征
    - 原因：视频流行度随着时间的分布是高度非稳态变化的。用户倾向观看最新的视频，而忽略与其的相关性。下图绿色曲线为流行度的经验分布。而在训练时，由于选取的是历史数据，也就是给定时间段内播放量的均值，这会导致模型对视频播放量预测值的期望趋于平均热度（蓝色线）
    <div align=center>
    <img src="https://img-blog.csdnimg.cn/15dfce743bd2490a8adb21fd3b2b294e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
    </div>

    - 定义：\(t_{max} - t\),其中\(t_{max}\)为训练数据中所有样本的时间最大值，$t$为当前样本时间
    - 时间bias：一个视频上传到样本生成的时间跨度。对某个视频的不同样本，图中的定义是等价的。因为和是常数。$ t_{\text {video age }}+t_{\text {example age }}=\text { Const } $。也就是视频上传时间到采样时间右端点这一跨度。
    但是example age可以在线上预测时设置为常数，也就是**所有的item是统一的**，只需要计算一次；而vedio age 与每个视频的上传时间有关，每个item都需要计算一次。并且，**不同的视频，对应的example age的范围是一致的**，仅仅依赖**训练数据的采样时间**，方便归一化操作。
    <div align=center>
    <img src="https://img-blog.csdnimg.cn/10475c194c0044a3a93b01a3193e294f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
    </div>

- **线上服务**
  <div align=center>
  <img src="https://img-blog.csdnimg.cn/86751a834d224ad69220b5040e0e03c9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBATWlyYWNsZTgwNzA=,size_1,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述" style="zoom:70%;" /> 
  </div>
  
  - k近邻搜索：提前将用户与视频的embedding存储，在用户上线后进行匹配。常用的检索工具有annoy、faiss

## 双塔召回

### 经典双塔
- **模型结构**
分为用户塔与物品塔，分别根据两侧的特征输入，利用DNN得到各自的embedding表示。再计算两者的相似度。
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522103456450.png" style="zoom:60%;"/>
</div>

相应被抽取的概率值计算如下，$s(x,y)$表示两个向量的相似度，$P(y|x;\theta)$表示预测类别的概率，$M$表示物料库所有的item。

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522110742879.png" style="zoom:60%;"/>
</div>

- **效果与缺陷**：整体召回的速度非常快，能够满足实际的需求，相应的代价是牺牲模型的部分精准性，因为两侧没有特征交叉。

### SENet双塔

- **模型结构**

$$SENet$$

<div align=center>
<img src="https://img-blog.csdn.net/20170916211038886?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxNDM4MDE2NQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" style="zoom:80%;"/>
</div>

$$
\downarrow
$$

$$ SENet双塔 $$

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220522152508824.png" style="zoom:70%;"/>
</div>

- SENet
  - Squeeze阶段：对embedding信息做汇总与压缩，也就是求均值
  $$
  z_i = F_{sq}(e_i) = \frac{1}{k} \sum_{t=1}^k e_i^{(t)}$$

  其中k表示Embedding的维度，Squeeze阶段是将每个特征的Squeeze转换成单一的数值。

  - Excitation阶段：这阶段是根据上一阶段得到的向量进行缩放，即将上阶段的得到的 $1 \times f$ 的向量$Z$先压缩成 $1 \times \frac{f}{r}$ 长度，然后在放回到  $1 \times f$ 的维度，其中$r$表示压缩的程度。这个过程的具体操作就是经过两层DNN。
    ​                                                                  $$A = F_{ex}(Z) = \sigma_2(W_2\sigma_1(W_1Z)) $$
    该过程可以理解为：对于当前所有输入的特征，通过相互发生关联，来**动态地判断哪些特征重要，哪些特征不重要**，而这体现在Excitation阶段的输出结果 $A$，其反应每个特征对应的**重要性权重**。

  - Re-weight阶段：是将Excitation阶段得到的每个特征对应的权重 $A$ 再乘回到特征对应的Embedding里，就完成了对特征重要性的加权操作。

  ​																		$$V=F_{ReWeight }(A,E)=[a_1 \cdot e_1,⋯,a_f \cdot e_f]=[v_1,⋯,v_f]$$

- SENet双塔的有效性：在底层过滤了特征中的无效低频特征，使得双塔在高层交互时仍然有较多的有用信息。当然，也可以在各自的塔中增加多通道，也就是多个SENet+DNN的组合，对各自的特征从不同的兴趣方面进行提取。

### 多目标双塔

根据业务中不同的评价指标，比如关注、点赞等行为，需要建立不同的塔得到相应的结果，再对所有塔的损失进行优化。具体如下图。在两侧分别通过多个通道为**每一个任务**得到一个对应的user embedding 与item embedding，再针对不同的优化目标计算相应的相似度以及损失。最终的目的是优化多任务的损失。
<div align=center>
<img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220523113206177.png" style="zoom:60%;"/>
</div>

### 细节问题

- **归一化与温度系数**：对user与item端输出的embedding做归一化，并对最后的内积结果除温度系数
  - 归一化：对两侧的输出做l2归一化.因为向量点积距离为非度量空间，不满足三角不等式，且向量**内积不保序**；通过归一化将点击行为转换为欧式距离。
  $$
  \begin{aligned}
  u(x,\theta) \leftarrow &= \frac{u(x,\theta)}{||u(x,\theta)||_2}\\
  v(x,\theta) \leftarrow &= \frac{v(x,\theta)}{||v(x,\theta)||_2}
  \end{aligned}
  $$

  - 温度系数：对归一化的向量计算内积后，除固定的超参数\(r\)。
  $$
  s(u,v) = \frac{<u(x,\theta), v(x,\theta)>}{r}
  $$

#### 负样本采样

与排序模型不同，召回面对的是全部item，因此不能像排序一样只考虑没有被点击的item，需要保证负样本在线下线上的分布尽量一致。也就是尽可能增加没有被曝光的item
- **全局随机采样**:从全局候选的item中选取一定数量的item作为负样本。但由于item存在八二定律，也就是少数热门物料占据大部分曝光与点击。因此纯随机方法只能让模型学习一些粗粒度的差异。
- **全局随机采样 + 热门打压**：对有着高曝光与点击的item进行打压，也就是欠采样。让模型更关注非热门item。同时还应当在热门item做负样本时进行适当的过采样，因为热门的item与用户的兴趣相似度较高，模型需要更注重在item与用户兴趣相似时，怎么区分。
- **Hard Negative增强样本**：选取一部分匹配度适中的item，用以加强模型在训练时的难度，从而让模型学习到更多的细粒度的信息。也就是正负样本在某些方面是具有一定的相似性的。
- **Batch内随机选择负采样**：将batch内除正样本之外的其他item作为负样本。也就是将其他样本的正样本随机采样为自己的负样本。潜在的问题是：如果batch的分布与实际差异较大会出现问题；并且batch内仍然存在热门效应，需要对热门物品进行打压。

### Youtube双塔

- **原理**：给定一个查询集 $Query: \left\{x_{i}\right\}_{i=1}^{N}$ 和一个物品集 $Item:\left\{y_{j}\right\}_{j=1}^{M}$。
  + $x_{i} \in X,\quad y_{j} \in \mathcal{Y}$ 是由多种特征组成的高维混合体。
  + 推荐的目标是对于给定一个 $query$，检索到一系列 $item$ 子集用于后续排序任务。

- **结构**：
<div align=center>
<img src="https://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220506202824884.png" alt="image-20220506202824884" style="zoom:40%;" />
</div>
通过对用户与物品分别建立不同的模型，投影到相同维度的区间

$$
u: X \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{k}\\
v: y \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{k}
$$

模型的输出是用户与物品向量之间的内积，其中$\theta$是待学习参数。
$$
s(x, y)=\langle u(x, \theta), v(y, \theta)\rangle
$$
样本集表示成$\{query, item, reward \}$的形式，如下所示。 $r_i$ 可以扩展来捕获用户对不同候选物品的参与度。
$$
\mathcal{T}:=\left\{\left(x_{i}, y_{i}, r_{i}\right)\right\}_{i=1}^{T}
$$

- **流程**：
1.  给定用户 $x$，基于 softmax 函数从物料库 $M$ 中选中候选物品 $y$ 的概率为：
    $$
    \mathcal{P}(y \mid x ; \theta)=\frac{e^{s(x, y)}}{\sum_{j \in[M]} e^{s\left(x, y_{j}\right)}}
    $$

    * 考虑到相关奖励 $r_i$ ，加权对数似然函数的定义如下：  

      $$
      L_{T}(\theta):=-\frac{1}{T} \sum_{i \in[T]} r_{i} \cdot \log \left(\mathcal{P}\left(y_{i} \mid x_{i} ; \theta\right)\right)
      $$
2.  原表达式 $\mathcal{P}(y \mid x ; \theta)$ 中分母需要遍历所有的物品，计算成本太高，故对分母中的物品要进行负采样。为了提高负采样的速度，一般是直接从训练样本所在 Batch 中进行负样本选择。于是有：
    $$
    \mathcal{P}_{B}\left(y_{i} \mid x_{i} ; \theta\right)=\frac{e^{s\left(x_{i}, y_{i}\right)}}{\sum_{j \in[B]} e^{s\left(x_{i}, y_{j}\right)}}
    $$
    * 其中，$B$ 表示与样本 $\{x_i,y_j\}$ 同在一个 Batch 的物品集合。
    * 举例来说，对于用户1，Batch 内其他用户的正样本是用户1的负样本。
3.  一般而言，负采样分为 Easy Negative Sample 和 Hard Negative Sample。Easy Negative Sample 是直接从全局物料库中随机选取负样本。
   由于每个用户感兴趣的物品有限，而物料库又往往很大，故即便从物料库中随机选取负样本，也大概率是用户不感兴趣的。在真实场景中，存在八二定律，随机选择负样本往往选中的是冷门物品。这就会造成马太效应，热门物品更热，冷门物品更冷。一种解决方式是，在对训练样本进行负采样时，提高热门物品被选为负样本的概率，工业界的经验做法是**物品被选为负样本的概率正比于物品点击次数的 0.75 次幂**。
   在 Batch 内进行负采样，存在热门物品被选为负样本的概率过高，导致热门物品被过度打压的问题。
   本文为了避免对热门物品进行过度惩罚，进行了纠偏。公式如下。在内积 $s(x_i,y_j)$ 的基础上，减去了物品 $j$ 的采样概率的对数。
      $$
      s^{c}\left(x_{i}, y_{j}\right)=s\left(x_{i}, y_{j}\right)-\log \left(p_{j}\right)
      $$

4. 纠偏后，物品 $y$ 被选中的概率为：
    $$
    \mathcal{P}_{B}^{c}\left(y_{i} \mid x_{i} ; \theta\right)=\frac{e^{s^{c}\left(x_{i}, y_{i}\right)}}{e^{s^{c}\left(x_{i}, y_{i}\right)}+\sum_{j \in[B], j \neq i} e^{s^{c}\left(x_{i}, y_{j}\right)}}
    $$

    + 此时，batch loss function 的表示式如下：

    $$
    L_{B}(\theta):=-\frac{1}{B} \sum_{i \in[B]} r_{i} \cdot \log \left(\mathcal{P}_{B}^{c}\left(y_{i} \mid x_{i} ; \theta\right)\right)
    $$
    + 通过 SGD 和学习率，来优化模型参数 $\theta$ ：

    $$
    \theta \leftarrow \theta-\gamma \cdot \nabla L_{B}(\theta)
    $$

5. Normalization and Temperature

    * 最后一层，得到用户和物品的特征 Embedding 表示后，再进行进行 $l2$ 归一化。本质上，其实是将用户和物品的向量内积转换为了余弦相似度
      $$
      \begin{aligned}
      u(x, \theta) \leftarrow u(x, \theta) /\|u(x, \theta)\|_{2}\\
      v(y, \theta) \leftarrow v(y, \theta) /\|v(y, \theta)\|_{2}
      \end{aligned}
      $$

    * 对于内积的结果，再除以温度参数 $\tau$：
      $$
      s(x, y)=\langle u(x, \theta), v(y, \theta)\rangle / \tau
      $$

      + 论文提到，这样有利于提高预测准确度。
      + 从实验结果来看，温度参数 $\tau$ 一般小于 $1$，所以感觉就是**放大了内积结果**。

- **流频估计算法**
考虑一个随机的数据batch，每个 batch 中包含一组物品。现在的问题是如何估计一个 batch 中物品 $y$ 的选取概率。具体方法如下：

  + 利用全局步长，将对物品采样频率 $p$ 转换为 对 $\delta$ 的估计，其中 $\delta$ 表示连续两次采样物品之间的平均步数。
  + 例如，某物品平均 50 个步后会被采样到，那么采样频率 $p=1/\delta=0.02$ 。

**具体的实现方法为：**

1. 建立两个大小为 $H$ 的数组 $A,B$ 。

2. 通过哈希函数 $h(\cdot)$ 把每个物品映射为 $[H]$ 范围内的整数。

3. 数组 $A$ 中存放的 $A[h(y)]$ 表示物品 $y$ **上次被采样**的时间， 数组 $B$ 中存放的 $B[h(y)]$ 表示物品 $y$ 的**全局步长**。

   + 假设在第 $t$ 步时采样到物品 $y$，则 $A[h(y)]$ 和 $B[h(y)]$ 的更新公式为：
     $$
     B[h(y)] \leftarrow(1-\alpha) \cdot B[h(y)]+\alpha \cdot(t-A[h(y)])
     $$

   + 在$B$ 被更新后，将 $t$ 赋值给 $A[h(y)]$ 。

4. 对整个batch数据采样后，取数组 $B$ 中 $B[h(y)]$ 的倒数，作为物品 $y$ 的采样频率，即：
   $$
   \hat{p}=1 / B[h(y)]
   $$

- **多重哈希**：为了解决物品较多时，映射的整数相同导致哈希碰撞的问题，使用多个哈希函数，选取所有估计值的最大值表示连续两次被采样的步长。
  - **具体的算法流程：**

  1. 分别建立 $m$ 个大小为 $H$ 的数组 $\{A\}_{i=1}^{m}$，$\{B\}_{i=1}^{m}$，一组对应的独立哈希函数集合 $\{h\}_{i=1}^{m}$ 。

  2. 通过哈希函数 $h(\cdot)$ 可以把每个物品映射为 $[H]$ 范围内的整数。对于给定的物品 $y$，哈希后的整数记为$h(y)$

  3. 数组 $A_i$ 中存放的 $A_i[h(y)]$ 表示在第 $i$ 个哈希函数中物品 $y$ 上次被采样的时间。数组 $B_i$ 中存放的 $B_i[h(y)]$ 表示在第 $i$ 个哈希函数中物品 $y$ 的全局步长。

  4. 假设在第 $t$ 步采样到物品 $y$，分别对 $m$ 个哈希函数对应的 $A[h(y)]$ 和 $B[h(y)]$ 进行更新：
     $$
     \begin{aligned}
     & B_i[h(y)] \leftarrow(1-\alpha) \cdot B_i[h(y)]+\alpha \cdot(t-A_i[h(y)])\\ \\
     & A_i[h(y)]\leftarrow t
     \end{aligned}
     $$

  5. 对整个 batch 数据采样后，取 $\{B\}_{i=1}^{m}$ 中最大的 $B[h(y)]$ 的倒数，作为物品 $y$ 的采样频率，即：

  $$
  \hat{p}=1 / \max _{i}\left\{B_{i}[h(y)]\right\}
  $$

- **YouTube**召回模型：
  ![image-20220506224501697](https://ryluo.oss-cn-chengdu.aliyuncs.com/%E5%9B%BE%E7%89%87image-20220506224501697.png)
在任何时间点，用户正在观看的视频，即**种子视频**，都会提供有关用户当前兴趣的强烈信号。因此，该模型利用了大量种子视频特征以及用户的观看历史记录。候选塔是为了从候选视频特征中学习而构建的。

* Training Label

  * 视频点击被用作**正面标签**。对于每次点击，都构建一个 rewards 来反映用户对视频的不同程度的参与。
  * $r_i$ = 0：观看时间短的点击视频；$r_i$ = 1：表示观看了整个视频。
  
* Video Features

  * YouTube 使用的视频特征包括 categorical 特征和 dense 特征。

    * 例如 categorical 特征有 video id 和 channel id 。
    * 对于 categorical 特征，都会创建一个嵌入层以将每个分类特征映射到一个 Embedding 向量。
    * 通常 YouTube 要处理两种类别特征，分别是 one-hot 和 multi-hot。

* User Features

  * 使用**用户观看历史记录**来捕捉 seed video 之外的兴趣。将用户**最近观看的 k个视频**视为一个词袋（BOW)，然后将它们的 Embedding 平均。
  * 在查询塔中，最后将用户和历史 seed video 的特征进行融合，并送入输入前馈神经网络。

## 图召回
### EGES
==主要贡献:引入side information解决实际中数据稀疏与冷启动的问题==
- **传统方法存在的问题**:
  - 可扩展性：现有的推荐方法无法扩展到拥有众多用户与商品的情况。
  - 稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于部分商品，存在大量商品很少被用户交互。
  - 冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。 

#### 模型结构与原理
方法是基于DeepWalk模型进行改造.目的是通过物品图G学习映射函数$f:V -> R^d$,将节点映射成Embedding.首先基于随机游走为图中的每个节点生成序列,再通过skipGram方法学习每个物品的embedding.
- **构建item-item图**
  先根据用户的session行为(指定时间跨度)序列构建网络结构,序列中相邻的item之间存在带有权重的边,权重是所有的用户序列中,该item对共同出现的次数.同时需要对item与user去噪:item点击停留时间过短|过于活跃的用户|频繁修改的物品.
<div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328133138263.png" style="zoom:80%;"/>
</div>

- **图嵌入(BGE)**
  首先随机游走得到物品序列.随机游走的概率计算方式如下.其中$M_{ij}$为边$e_{ij}$上的权重(也就是item对(i,j)出现的次数)，$N_{+}(v_i)$表示节点$v_i$所有邻居节点集合，随机游走的转移概率是对每个节点所有邻接边权重的归一化结果。
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328144516898.png" style="zoom:80%;"/>
  </div>
  通过随机游走,得到序列.然后为每一个item生成对应的embedding.假设物品之间是独立的,并进行负采样.优化目标就变为下图.
  <div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220418142135912.png" style="zoom:47%;"/>
  </div>
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328145318718.png" style="zoom:80%;"/>
  </div>

- **基于side information的图嵌入(GES)**
  上面的模型无法很好的解决冷启动问题,因为新的物品加入后并没有与用户进行交互,并不会在item图中出现,也就是没法学习相应的embedding.因此模型加入Side Information(类别|店铺|价格等额外信息)辅助训练,通过side information 学习到的embedding代表具体的商品,这样相似的side information能在空间上有相似的表示.
  具体来说,在随机游走之后,每个商品由对应的id以及属性组成,也就是对于序列中的每一个物品可以得到$W^0_V,...W_V^n$,（n+1）个向量表示，$W^0_V$表示物品v，剩下是side information的embedding.将side information整合成一个整体来表示物品,也就是$H_v = \frac{1}{n+1}\sum_{s=0}^n W^s_v$

- **Enhanced GES**
  实际中不同的side information对embedding的贡献不是相等的,因此更应该使用带有权重的池化操作,也就是:
  <div align=center>
    <img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328154950289.png" style="zoom:80%;"/>
  </div>

  具体的计算公式是,其中$a_i$为用于计算权重的参数向量
  $$
  H_v = \frac{\sum_{j=0}^n e^{a_v^j} W_v^j}{\sum_{j=0}^n e^{a_v^j}}
  $$
  先对$a_v^j$做指数变换,以确保每个边界信息的贡献度都可以大于0,然后做归一化,使得每个特征的权重在[0,1]内.在获取对应的权重之后对各特征做加权聚合,进而得到损失函数为:
  $$
  L(v,u,y)=-[ylog( \sigma (H_v^TZ_u)) + (1-y)log(1 - \sigma(H_v^TZ_u))]
  $$

### PinSAGE
#### GraphSAGE
用于解决图中的节点以及图的结构不断发生变化的情况,GraphSAGE可以通过聚合邻居信息的方式为给定的节点学习相应的embedding表示.具体操作如下:
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220423094435223.png" style="zoom:90%;"/>
</div>

- $h_v^0$表示图节点的初始化表示，等同于节点自身的特征。
- $h_v^k$表示第k层卷积后的节点表示，其来源于两个部分：
  - 第一部分来源于节点v的邻居节点集合$N(v)$，利用邻居节点的第k-1层卷积后的特征$h_u^{k-1}$进行 （ $\sum_{u \in N(v)} \frac{h_u^{k-1}}{|N(v)|}$ ）后，在进行线性变换。这里**借助图上的边将邻居节点的信息通过边关系聚合到节点表示中(简称卷积操作)**。
  - 第二部分来源于节点v的第k-1层卷积后的特征$h_v^{k-1}$，进行线性变换。总的来说图卷积的思想是**在对自身做多次非线性变换时，同时利用边关系聚合邻居节点信息。**
- 最后一次卷积结果作为节点的最终表示$Z_v$。
  
**采样和聚合**
分为两步:首先从所有邻居节点中找出用于聚合的邻居节点集合;然后对采样后的结果进行聚合操作
- **邻居采样**
  根据中心节点集合$B^k$,对集合中每个中心节点使用随机采样,采取固定数目的邻居节点S个,如果该中心点的邻居节点数大于S,则无放回抽样,反之有放回.

  进行邻居采样并固定采样数量S主要是因为：1. 采样邻居节点避免了在全图的搜索以及使用全部邻居节点所导致计算复杂度高的问题；2. 可以通过采样使得部分节点更同质化，即两个相似的节点具有相同表达形式。3. 采样固定数量是保持每个batch的计算占用空间是固定的，方便进行批量训练。

- **聚合函数**(要求构建的函数具有对称性,也就是输入的顺序不影响输出的结果,同时表达能力要求较强)
  - Mean 聚合：首先会对邻居节点按照**element-wise**进行均值聚合，然后将当前节点k-1层得到特征$h_v^{k-1}$与邻居节点均值聚合后的特征 $MEAN(h_u^k | u\in N(v))$**分别**送入全连接网络后**相加**得到结果。
  - Convolutional 聚合：这是一种基于GCN聚合方式的变种，首先对邻居节点特征和自身节点特征求均值，得到的聚合特征送入到全连接网络中。与Mean不同的是，这里**只经过一个全连接层**。
  - LSTM聚合：由于LSTM可以捕捉到序列信息，因此相比于Mean聚合，这种聚合方式的**表达能力更强**；但由于LSTM对于输入是有序的，因此该方法不具备**对称性**。作者对于无序的节点进行**随机排列**以调整LSTM所需的有序性。
  - Pooling聚合：对于邻居节点和中心节点进行一次非线性转化，将结果进行一次基于**element-wise**的**最大池化**操作。该种方式具有**较强的表达能力**的同时还具有**对称性**。

#### PinSAGE
==基于GraphSAGE的原理学习到聚合方法，并为每个图片(pin)学习一个向量表示，然后基于pin的向量表示做item2item的召回==
- **重要性采样**
  在采样时关注更加重要的邻居节点,也就是为每个邻居节点计算一个重要性权重,选TopK的邻居节点作为邻居集合.计算重要性的过程是，以目标节点为起点，进行random-walk，采样结束之后计算**所有节点访问数的L1-normalized作为重要性权重**，同时这个权重也会在聚合过程中加以使用(**加权聚合**).
- **聚合函数
  PinSAGE中的Convolve算法（单层图卷积操作）相当于GraphSAGE算法的聚合过程，在实际执行过程中通过对**每一层**执行一次图卷积操作以得到不同阶邻居的信息，具体过程如下图所示：
  <div align=center>
      <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406202027832.png" style="zoom:110%;"/>
  </div>

  上述的单层图卷积过程如下三步：

  1. 聚合邻居： 先将所有的邻居节点经过一次非线性转化(一层DNN)，再由聚合函数(Pooling聚合) $\gamma$（如元素平均，**加权和**等）将所有邻居信息聚合成目标节点的embedding。这里的加权聚合采用的是通过random-walk得到的重要性权重。
  2. 更新当前节点的embedding：将目标节点当前的向量 $z_u$ 与步骤1中聚合得到的邻居向量 $n_u$ 进行拼接，在通过一次非线性转化。
  3. **归一化操作**：对目标节点向量 $z_u$ 归一化,使得训练时更加稳定。
  
- **基于mini-batch堆叠多层图卷积**
因为实际场景中,用户交互图非常庞大,不可能在一张图上学习所有节点的信息,所以,对mini-batch的所有结点,通过采样的方式逐层寻找相关的邻居结点,再对每一层的结点做图卷积,从而从k阶邻居结点聚合信息
<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406204431024.png" style="zoom:60%;"/>
</div>
如上图所示：对于batch内的所有节点(图上最顶层的6个节点)，依次**根据权重采样**，得到batch内所有节点的一阶邻居(图上第二层的所有节点)；然后对于所有一阶邻居再次进行采样，得到所有二阶邻居(图上的最后一层)。节点采样阶段完成之后，与采样的顺序相反进行聚合操作。首先对二阶邻居进行单次图卷积，将二阶节点信息聚合已更新一阶节点的向量表示(其中小方块表示的是一层非线性转化)；其次对一阶节点再次进行图卷积操作，将一阶节点的信息聚合已更新batch内所有节点的向量表示。仅此对于一个batch内的所有的样本通过卷积操作学习到一个embedding，而每一个batch的学习过程中仅**利用与mini-batch内相关节点的子图结构。**

- **训练过程**
PinSage在训练时采用的是 Margin Hinge Loss 损失函数，主要的思想是**最大化正例embedding之间的相关性，同时还要保证负例之间相关性相比正例之间的相关性小于某个阈值(Margin)**。具体的公式如下：

<div align=center>
    <img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220406210833675.png" style="zoom:100%;"/>
</div>

其中$Z_p$是学习得到的目标节点embedding，$Z_i$是与目标节点相关item的embedding，$Z_{n_k}$是与目标节点不相关item的embedding，$\Delta$为margin值，具体大小需要调参。

对于正样本而言，文中的定义是如果用户在点击的 item q之后**立即点击**了 item i，即认为 < q, i >构成正样本对。具体地，代码中将所有的训练样本构造成用户-项目二部图，然后对batch内的每个 item q，根据item-user-item的元路径进行随机游走，得到被**同一个用户交互过的 item i**，因此组成<q,i>正样本对。

由于模型是用于 item to item的召回，因此优化目标是与正样本之间的表示尽可能的相近，与负样本之间的表示尽可能的远。而图卷积操作会使得具有邻接关系的节点表示具有**同质性**，因此结合这两点，就需要在构建图结构的时，要将**训练样本之间可能存在的边在二部图上删除**，避免因为边的存在使得因卷积操作而导致的信息泄露。

- **负采样**

召回模型最主要的任务是从候选集合中选出用户可能感兴趣的item，直观的理解就是让模型将用户喜欢的和不喜欢的进行区分。然而由于候选集合的庞大数量，许多item之间十分相似，导致模型划分出来用户喜欢的item中会存在一些难以区分的item(即与用户非常喜欢item比较相似的那一部分)。有两种方法:

  - easy 负样本：这里对于mini-batch内的所有pair(训练样本对)会**共享500负样本**，这500个样本从batch之外的所有节点中随机采样得到。这么做可以减少在每个mini-batch中因计算所有节点的embedding所需的时间，文中指出这和为每个item采样一定数量负样本无差异。==用于加速模型收敛到一定范围,也就是模型具有初步的学习能力==
  - hard 负样本：这里使用hard 负样本的原因是根据实际场景的问题出发，模型需要从2百万 item 中识别出最相似的那一个 item。也就是说模型的区分能力不够细致，为了解决这个问题，加入了一些hard样本。hard 负样本是与 q 相似 以及和 i 不相似的物品，具体地的生成方式是将图上的节点计算相对节点 q 的个性化PageRank分值，根据分值的排序随机从2000~5000的位置选取节点作为负样本。==这用来帮助模型提升细粒度方面的能力==